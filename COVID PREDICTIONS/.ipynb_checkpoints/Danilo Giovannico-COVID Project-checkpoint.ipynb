{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DANILO GIOVANNICO - COVID PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21870,
     "status": "ok",
     "timestamp": 1582444037579,
     "user": {
      "displayName": "Ran Kremer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2_ZiPPU7rQBIvIt172EuazLz5955iIqYS5NAMAQ=s64",
      "userId": "05457805718113099013"
     },
     "user_tz": -120
    },
    "id": "piXlMqoHdl5b",
    "outputId": "f3ee89aa-1928-412c-f2f3-fde513d1d3fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['log', 'norm', 'beta', 'exp', 'datetime', 'sqrt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, exp, sqrt\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "%pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcursors\n",
    "\n",
    "# Starting from here, we code in R. \n",
    "# 여기서부터 R로 코딩을 시작합니다. \n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "base = importr('base')\n",
    "base._libPaths()[0]\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1S90bdBVIaK"
   },
   "source": [
    "# PREPROCESSING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1667,
     "status": "ok",
     "timestamp": 1582445342591,
     "user": {
      "displayName": "Ran Kremer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB2_ZiPPU7rQBIvIt172EuazLz5955iIqYS5NAMAQ=s64",
      "userId": "05457805718113099013"
     },
     "user_tz": -120
    },
    "id": "qHa4dZtoAV09",
    "outputId": "921e72b1-caac-491b-fab9-c26f54c1e411"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>stato</th>\n",
       "      <th>codice_regione</th>\n",
       "      <th>denominazione_regione</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ricoverati_con_sintomi</th>\n",
       "      <th>terapia_intensiva</th>\n",
       "      <th>totale_ospedalizzati</th>\n",
       "      <th>isolamento_domiciliare</th>\n",
       "      <th>...</th>\n",
       "      <th>deceduti</th>\n",
       "      <th>casi_da_sospetto_diagnostico</th>\n",
       "      <th>casi_da_screening</th>\n",
       "      <th>totale_casi</th>\n",
       "      <th>tamponi</th>\n",
       "      <th>casi_testati</th>\n",
       "      <th>note</th>\n",
       "      <th>ingressi_terapia_intensiva</th>\n",
       "      <th>note_test</th>\n",
       "      <th>note_casi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>13</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>42.351222</td>\n",
       "      <td>13.398438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>17</td>\n",
       "      <td>Basilicata</td>\n",
       "      <td>40.639471</td>\n",
       "      <td>15.805148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>18</td>\n",
       "      <td>Calabria</td>\n",
       "      <td>38.905976</td>\n",
       "      <td>16.594402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>15</td>\n",
       "      <td>Campania</td>\n",
       "      <td>40.839566</td>\n",
       "      <td>14.250850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>8</td>\n",
       "      <td>Emilia-Romagna</td>\n",
       "      <td>44.494367</td>\n",
       "      <td>11.341721</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data stato  codice_regione denominazione_regione        lat  \\\n",
       "0  2020-02-24T18:00:00   ITA              13               Abruzzo  42.351222   \n",
       "1  2020-02-24T18:00:00   ITA              17            Basilicata  40.639471   \n",
       "2  2020-02-24T18:00:00   ITA              18              Calabria  38.905976   \n",
       "3  2020-02-24T18:00:00   ITA              15              Campania  40.839566   \n",
       "4  2020-02-24T18:00:00   ITA               8        Emilia-Romagna  44.494367   \n",
       "\n",
       "        long  ricoverati_con_sintomi  terapia_intensiva  totale_ospedalizzati  \\\n",
       "0  13.398438                       0                  0                     0   \n",
       "1  15.805148                       0                  0                     0   \n",
       "2  16.594402                       0                  0                     0   \n",
       "3  14.250850                       0                  0                     0   \n",
       "4  11.341721                      10                  2                    12   \n",
       "\n",
       "   isolamento_domiciliare  ...  deceduti  casi_da_sospetto_diagnostico  \\\n",
       "0                       0  ...         0                           NaN   \n",
       "1                       0  ...         0                           NaN   \n",
       "2                       0  ...         0                           NaN   \n",
       "3                       0  ...         0                           NaN   \n",
       "4                       6  ...         0                           NaN   \n",
       "\n",
       "   casi_da_screening  totale_casi  tamponi  casi_testati  note  \\\n",
       "0                NaN            0        5           NaN   NaN   \n",
       "1                NaN            0        0           NaN   NaN   \n",
       "2                NaN            0        1           NaN   NaN   \n",
       "3                NaN            0       10           NaN   NaN   \n",
       "4                NaN           18      148           NaN   NaN   \n",
       "\n",
       "   ingressi_terapia_intensiva  note_test  note_casi  \n",
       "0                         NaN        NaN        NaN  \n",
       "1                         NaN        NaN        NaN  \n",
       "2                         NaN        NaN        NaN  \n",
       "3                         NaN        NaN        NaN  \n",
       "4                         NaN        NaN        NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"../DATASET/COVID-19/dati-regioni/dpc-covid19-ita-regioni.csv\", delimiter = ',')\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>stato</th>\n",
       "      <th>denominazione_regione</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>totale_positivi</th>\n",
       "      <th>totale_casi</th>\n",
       "      <th>deceduti</th>\n",
       "      <th>dimessi_guariti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>42.351222</td>\n",
       "      <td>13.398438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Basilicata</td>\n",
       "      <td>40.639471</td>\n",
       "      <td>15.805148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Calabria</td>\n",
       "      <td>38.905976</td>\n",
       "      <td>16.594402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Campania</td>\n",
       "      <td>40.839566</td>\n",
       "      <td>14.250850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-24T18:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Emilia-Romagna</td>\n",
       "      <td>44.494367</td>\n",
       "      <td>11.341721</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  data stato denominazione_regione        lat       long  \\\n",
       "0  2020-02-24T18:00:00   ITA               Abruzzo  42.351222  13.398438   \n",
       "1  2020-02-24T18:00:00   ITA            Basilicata  40.639471  15.805148   \n",
       "2  2020-02-24T18:00:00   ITA              Calabria  38.905976  16.594402   \n",
       "3  2020-02-24T18:00:00   ITA              Campania  40.839566  14.250850   \n",
       "4  2020-02-24T18:00:00   ITA        Emilia-Romagna  44.494367  11.341721   \n",
       "\n",
       "   totale_positivi  totale_casi  deceduti  dimessi_guariti  \n",
       "0                0            0         0                0  \n",
       "1                0            0         0                0  \n",
       "2                0            0         0                0  \n",
       "3                0            0         0                0  \n",
       "4               18           18         0                0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleared_dataframe = dataframe[['data', 'stato','denominazione_regione','lat','long','totale_positivi','totale_casi','deceduti','dimessi_guariti']]\n",
    "cleared_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>population</th>\n",
       "      <th>2020-02-24</th>\n",
       "      <th>2020-02-25</th>\n",
       "      <th>2020-02-26</th>\n",
       "      <th>2020-02-27</th>\n",
       "      <th>2020-02-28</th>\n",
       "      <th>2020-02-29</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-12-19</th>\n",
       "      <th>2020-12-20</th>\n",
       "      <th>2020-12-21</th>\n",
       "      <th>2020-12-22</th>\n",
       "      <th>2020-12-23</th>\n",
       "      <th>2020-12-24</th>\n",
       "      <th>2020-12-25</th>\n",
       "      <th>2020-12-26</th>\n",
       "      <th>2020-12-27</th>\n",
       "      <th>2020-12-28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>42.351222</td>\n",
       "      <td>13.398438</td>\n",
       "      <td>1305770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19195</td>\n",
       "      <td>19307</td>\n",
       "      <td>19739</td>\n",
       "      <td>20235</td>\n",
       "      <td>20705</td>\n",
       "      <td>21248</td>\n",
       "      <td>21408</td>\n",
       "      <td>21419</td>\n",
       "      <td>21507</td>\n",
       "      <td>21812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basilicata</td>\n",
       "      <td>40.639471</td>\n",
       "      <td>15.805148</td>\n",
       "      <td>556934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3760</td>\n",
       "      <td>3804</td>\n",
       "      <td>3865</td>\n",
       "      <td>3964</td>\n",
       "      <td>4120</td>\n",
       "      <td>4200</td>\n",
       "      <td>4251</td>\n",
       "      <td>4271</td>\n",
       "      <td>4280</td>\n",
       "      <td>4321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calabria</td>\n",
       "      <td>38.905976</td>\n",
       "      <td>16.594402</td>\n",
       "      <td>1924701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11999</td>\n",
       "      <td>12260</td>\n",
       "      <td>12511</td>\n",
       "      <td>12588</td>\n",
       "      <td>13099</td>\n",
       "      <td>13225</td>\n",
       "      <td>13308</td>\n",
       "      <td>13507</td>\n",
       "      <td>13665</td>\n",
       "      <td>13749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Campania</td>\n",
       "      <td>40.839566</td>\n",
       "      <td>14.250850</td>\n",
       "      <td>5785861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>92927</td>\n",
       "      <td>94031</td>\n",
       "      <td>95128</td>\n",
       "      <td>98167</td>\n",
       "      <td>100527</td>\n",
       "      <td>101601</td>\n",
       "      <td>102065</td>\n",
       "      <td>102580</td>\n",
       "      <td>103370</td>\n",
       "      <td>104549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emilia-Romagna</td>\n",
       "      <td>44.494367</td>\n",
       "      <td>11.341721</td>\n",
       "      <td>4467118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85872</td>\n",
       "      <td>87594</td>\n",
       "      <td>88011</td>\n",
       "      <td>91411</td>\n",
       "      <td>94188</td>\n",
       "      <td>96529</td>\n",
       "      <td>96910</td>\n",
       "      <td>100333</td>\n",
       "      <td>100659</td>\n",
       "      <td>101255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           region        lat       long population  2020-02-24  2020-02-25  \\\n",
       "0         Abruzzo  42.351222  13.398438    1305770           0           0   \n",
       "1      Basilicata  40.639471  15.805148     556934           0           0   \n",
       "2        Calabria  38.905976  16.594402    1924701           0           0   \n",
       "3        Campania  40.839566  14.250850    5785861           0           0   \n",
       "4  Emilia-Romagna  44.494367  11.341721    4467118           0           0   \n",
       "\n",
       "   2020-02-26  2020-02-27  2020-02-28  2020-02-29  ...  2020-12-19  \\\n",
       "0           0           0           0           0  ...       19195   \n",
       "1           0           0           0           0  ...        3760   \n",
       "2           0           0           0           0  ...       11999   \n",
       "3           0           0           0           0  ...       92927   \n",
       "4           0           0           0           0  ...       85872   \n",
       "\n",
       "   2020-12-20  2020-12-21  2020-12-22  2020-12-23  2020-12-24  2020-12-25  \\\n",
       "0       19307       19739       20235       20705       21248       21408   \n",
       "1        3804        3865        3964        4120        4200        4251   \n",
       "2       12260       12511       12588       13099       13225       13308   \n",
       "3       94031       95128       98167      100527      101601      102065   \n",
       "4       87594       88011       91411       94188       96529       96910   \n",
       "\n",
       "   2020-12-26  2020-12-27  2020-12-28  \n",
       "0       21419       21507       21812  \n",
       "1        4271        4280        4321  \n",
       "2       13507       13665       13749  \n",
       "3      102580      103370      104549  \n",
       "4      100333      100659      101255  \n",
       "\n",
       "[5 rows x 313 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['region','lat','long','population']\n",
    "for date in cleared_dataframe['data']:\n",
    "    if date.split('T')[0] not in header :\n",
    "        header.append(date.split('T')[0])\n",
    "        \n",
    "regions_array = cleared_dataframe['denominazione_regione'].iloc[:21]   \n",
    "lat_array = cleared_dataframe['lat'].iloc[:21]\n",
    "long_array = cleared_dataframe['long'].iloc[:21]\n",
    "population_array = ['1305770','556934','1924701','5785861','4467118','1211357','5865544','1543127',\n",
    "                    '10103969','1518400','302265','106951','117417','4341375','4008296','1630474',\n",
    "                    '4968410','3722729','880285','125501','4907704']\n",
    "\n",
    "confirmed_df = pd.DataFrame(columns=header)\n",
    "confirmed_df['region'] = regions_array\n",
    "confirmed_df['lat'] = lat_array\n",
    "confirmed_df['long'] = long_array\n",
    "confirmed_df['population'] = population_array\n",
    "for count, column in enumerate(confirmed_df.drop(['region','lat','long','population'], axis = 1)):\n",
    "    confirmed_df[column] = cleared_dataframe['totale_positivi'].iloc[count*21:(count+1)*21].tolist()\n",
    "confirmed_df.to_csv(r'confirmed_ts.csv', index = False, header=True)\n",
    "\n",
    "death_df = pd.DataFrame(columns=header)\n",
    "death_df['region'] = regions_array\n",
    "death_df['lat'] = lat_array\n",
    "death_df['long'] = long_array\n",
    "death_df['population'] = population_array\n",
    "for count, column in enumerate(death_df.drop(['region','lat','long','population'], axis = 1)):\n",
    "    death_df[column] = cleared_dataframe['deceduti'].iloc[count*21:(count+1)*21].tolist()\n",
    "death_df.to_csv(r'death_ts.csv', index = False, header=True)\n",
    "\n",
    "recover_df = pd.DataFrame(columns=header)\n",
    "recover_df['region'] = regions_array\n",
    "recover_df['lat'] = lat_array\n",
    "recover_df['long'] = long_array\n",
    "recover_df['population'] = population_array\n",
    "for count, column in enumerate(recover_df.drop(['region','lat','long','population'], axis = 1)):\n",
    "    recover_df[column] = cleared_dataframe['dimessi_guariti'].iloc[count*21:(count+1)*21].tolist()\n",
    "recover_df.to_csv(r'recover_ts.csv', index = False, header=True)\n",
    "\n",
    "recover_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION TO CREATE THE TIME SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts(df):\n",
    "    ts=df\n",
    "    ts=ts.drop(['lat','long','population'], axis=1)\n",
    "    ts.set_index('region')\n",
    "    ts=ts.T\n",
    "    ts.columns=ts.loc['region']\n",
    "    ts=ts.drop('region')\n",
    "    ts=ts.fillna(0)\n",
    "    ts=ts.reindex(sorted(ts.columns), axis=1)\n",
    "    return (ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>region</th>\n",
       "      <th>Abruzzo</th>\n",
       "      <th>Basilicata</th>\n",
       "      <th>Calabria</th>\n",
       "      <th>Campania</th>\n",
       "      <th>Emilia-Romagna</th>\n",
       "      <th>Friuli Venezia Giulia</th>\n",
       "      <th>Lazio</th>\n",
       "      <th>Liguria</th>\n",
       "      <th>Lombardia</th>\n",
       "      <th>Marche</th>\n",
       "      <th>...</th>\n",
       "      <th>P.A. Bolzano</th>\n",
       "      <th>P.A. Trento</th>\n",
       "      <th>Piemonte</th>\n",
       "      <th>Puglia</th>\n",
       "      <th>Sardegna</th>\n",
       "      <th>Sicilia</th>\n",
       "      <th>Toscana</th>\n",
       "      <th>Umbria</th>\n",
       "      <th>Valle d'Aosta</th>\n",
       "      <th>Veneto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>11694</td>\n",
       "      <td>5943</td>\n",
       "      <td>8359</td>\n",
       "      <td>80009</td>\n",
       "      <td>57299</td>\n",
       "      <td>12102</td>\n",
       "      <td>75491</td>\n",
       "      <td>5958</td>\n",
       "      <td>57908</td>\n",
       "      <td>9415</td>\n",
       "      <td>...</td>\n",
       "      <td>9107</td>\n",
       "      <td>1746</td>\n",
       "      <td>34870</td>\n",
       "      <td>53131</td>\n",
       "      <td>16015</td>\n",
       "      <td>33380</td>\n",
       "      <td>10969</td>\n",
       "      <td>3521</td>\n",
       "      <td>427</td>\n",
       "      <td>104022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-25</th>\n",
       "      <td>11867</td>\n",
       "      <td>5956</td>\n",
       "      <td>8529</td>\n",
       "      <td>80547</td>\n",
       "      <td>58980</td>\n",
       "      <td>12084</td>\n",
       "      <td>76074</td>\n",
       "      <td>5669</td>\n",
       "      <td>58710</td>\n",
       "      <td>9567</td>\n",
       "      <td>...</td>\n",
       "      <td>10564</td>\n",
       "      <td>1777</td>\n",
       "      <td>31497</td>\n",
       "      <td>53589</td>\n",
       "      <td>16320</td>\n",
       "      <td>33232</td>\n",
       "      <td>11269</td>\n",
       "      <td>3546</td>\n",
       "      <td>428</td>\n",
       "      <td>87385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-26</th>\n",
       "      <td>11885</td>\n",
       "      <td>5960</td>\n",
       "      <td>8561</td>\n",
       "      <td>80563</td>\n",
       "      <td>57287</td>\n",
       "      <td>12125</td>\n",
       "      <td>76294</td>\n",
       "      <td>5672</td>\n",
       "      <td>59622</td>\n",
       "      <td>9635</td>\n",
       "      <td>...</td>\n",
       "      <td>10566</td>\n",
       "      <td>1726</td>\n",
       "      <td>31557</td>\n",
       "      <td>53790</td>\n",
       "      <td>16400</td>\n",
       "      <td>33290</td>\n",
       "      <td>10878</td>\n",
       "      <td>3549</td>\n",
       "      <td>418</td>\n",
       "      <td>88842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>11816</td>\n",
       "      <td>5959</td>\n",
       "      <td>8578</td>\n",
       "      <td>80075</td>\n",
       "      <td>58175</td>\n",
       "      <td>12190</td>\n",
       "      <td>76438</td>\n",
       "      <td>5769</td>\n",
       "      <td>59327</td>\n",
       "      <td>9671</td>\n",
       "      <td>...</td>\n",
       "      <td>10580</td>\n",
       "      <td>1775</td>\n",
       "      <td>31062</td>\n",
       "      <td>53638</td>\n",
       "      <td>16415</td>\n",
       "      <td>33167</td>\n",
       "      <td>10800</td>\n",
       "      <td>3553</td>\n",
       "      <td>432</td>\n",
       "      <td>90021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>11545</td>\n",
       "      <td>5930</td>\n",
       "      <td>8701</td>\n",
       "      <td>79296</td>\n",
       "      <td>58298</td>\n",
       "      <td>12112</td>\n",
       "      <td>76070</td>\n",
       "      <td>5688</td>\n",
       "      <td>54765</td>\n",
       "      <td>9737</td>\n",
       "      <td>...</td>\n",
       "      <td>10607</td>\n",
       "      <td>1821</td>\n",
       "      <td>30303</td>\n",
       "      <td>53157</td>\n",
       "      <td>16344</td>\n",
       "      <td>33246</td>\n",
       "      <td>10284</td>\n",
       "      <td>3558</td>\n",
       "      <td>494</td>\n",
       "      <td>90942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "region      Abruzzo  Basilicata  Calabria  Campania  Emilia-Romagna  \\\n",
       "2020-12-24    11694        5943      8359     80009           57299   \n",
       "2020-12-25    11867        5956      8529     80547           58980   \n",
       "2020-12-26    11885        5960      8561     80563           57287   \n",
       "2020-12-27    11816        5959      8578     80075           58175   \n",
       "2020-12-28    11545        5930      8701     79296           58298   \n",
       "\n",
       "region      Friuli Venezia Giulia  Lazio  Liguria  Lombardia  Marche  ...  \\\n",
       "2020-12-24                  12102  75491     5958      57908    9415  ...   \n",
       "2020-12-25                  12084  76074     5669      58710    9567  ...   \n",
       "2020-12-26                  12125  76294     5672      59622    9635  ...   \n",
       "2020-12-27                  12190  76438     5769      59327    9671  ...   \n",
       "2020-12-28                  12112  76070     5688      54765    9737  ...   \n",
       "\n",
       "region      P.A. Bolzano  P.A. Trento  Piemonte  Puglia  Sardegna  Sicilia  \\\n",
       "2020-12-24          9107         1746     34870   53131     16015    33380   \n",
       "2020-12-25         10564         1777     31497   53589     16320    33232   \n",
       "2020-12-26         10566         1726     31557   53790     16400    33290   \n",
       "2020-12-27         10580         1775     31062   53638     16415    33167   \n",
       "2020-12-28         10607         1821     30303   53157     16344    33246   \n",
       "\n",
       "region      Toscana  Umbria  Valle d'Aosta  Veneto  \n",
       "2020-12-24    10969    3521            427  104022  \n",
       "2020-12-25    11269    3546            428   87385  \n",
       "2020-12-26    10878    3549            418   88842  \n",
       "2020-12-27    10800    3553            432   90021  \n",
       "2020-12-28    10284    3558            494   90942  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_confirmed=create_ts(confirmed_df)\n",
    "ts_death=create_ts(death_df)\n",
    "ts_recover=create_ts(recover_df)\n",
    "ts_confirmed.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PLOT (TOTAL POSITIVE, TOTAL DEATH, TOTAL RECOVERED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mplcursors._mplcursors.Cursor at 0x7feb643cbb10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=ts_confirmed.reindex(ts_confirmed.max().sort_values(ascending=False).index, axis=1)\n",
    "p.iloc[:,7:8].plot(marker='o',linewidth=1,markersize=3,figsize=(16,8)).set_title('Daily Total Confirmed - Puglia',fontdict={'fontsize': 30})\n",
    "p.iloc[:,0:10].plot(marker='o',linewidth=1,markersize=3,figsize=(16,8)).set_title('Daily Total Confirmed - Major areas',fontdict={'fontsize': 30})\n",
    "\n",
    "p_d=ts_death.reindex(ts_confirmed.mean().sort_values(ascending=False).index, axis=1)\n",
    "p_d.iloc[:,7:8].plot(marker='o',linewidth=1,markersize=3,figsize=(16,8)).set_title('Daily Total Death - Puglia',fontdict={'fontsize': 30})\n",
    "p_d.iloc[:,0:10].plot(marker='o',linewidth=1,markersize=3,figsize=(16,8)).set_title('Daily Total Death - Major areas',fontdict={'fontsize': 30})\n",
    "\n",
    "p_r=ts_recover.reindex(ts_confirmed.mean().sort_values(ascending=False).index, axis=1)\n",
    "p_r.iloc[:,7:8].plot(marker='o',linewidth=1,markersize=3,figsize=(16,8)).set_title('Daily Total Recoverd - Puglia',fontdict={'fontsize': 30})\n",
    "p_r.iloc[:,0:10].plot(marker='o',linewidth=1,markersize=3,figsize=(16,8)).set_title('Daily Total Recoverd - Major areas',fontdict={'fontsize': 30})\n",
    "\n",
    "mplcursors.cursor(hover=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID SPREAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE THE CSV WITH THE DATA TO PASS TO THE FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_r=ts_confirmed.reset_index()\n",
    "ts_r=ts_r.rename(columns = {'index':'date'})\n",
    "ts_r['date']=pd.to_datetime(ts_r['date'] ,errors ='coerce')\n",
    "ts_r.tail()\n",
    "ts_r.to_csv(r'ts_r.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KALMAN FILTER WITH R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pracma)\n",
    "library(Metrics)\n",
    "library(readr)\n",
    "all<- read.csv(\"/Users/danilogiovannico/Desktop/PROGETTO-Estimation\\ and\\ Data\\ Analysis\\ with\\ Applications/COVID\\ PREDICTIONS/ts_r.csv\")\n",
    "all$X1<-NULL\n",
    "date<-all[,1, drop=FALSE]\n",
    "# La funzione rbind () combina vettori, matrici o frame di dati per righe\n",
    "date<-rbind(date, data.frame(date = format(as.Date(all[nrow(all),1])+1)))\n",
    "#date[nrow(date) + 1,1] <- as.Date(all[nrow(all),1])+1\n",
    "pred_all<-NULL\n",
    "# ncol ritorna il numero di colonne presenti nel dataset, nrow il numero di righe\n",
    "# Iteriamo per colonna sulle regioni\n",
    "for (n in 2:ncol(all)-1) {\n",
    "    # Costruisco la time series\n",
    "    #La funzione ts () convertirà un vettore numerico in un oggetto della serie temporale R. \n",
    "    #Il formato è ts (vector, start=, end=, frequency=) dove inizio e fine sono i tempi della prima e dell'ultima osservazione e la frequenza è \n",
    "    #il numero di osservazioni per unità di tempo (1 = annuale, 4 = trimestrale, 12 = mensile, ecc.).\n",
    "    Y<-ts(data = all[n+1], start = 1, end =nrow(all)+1) \n",
    "    # Time Step\n",
    "    t<-1\n",
    "    # Costruiamo la matrice A 2x2\n",
    "    A<-matrix(c(1,0,t,1),2,2)\n",
    "    #Matrice di osservazione\n",
    "    H<-matrix(c(1,0),1,2)\n",
    "    # Condizioni iniziali filtro di Kalman\n",
    "    # Vettore di stato 2x1\n",
    "    x0_0<-matrix(c(0,0),2,1)\n",
    "    # Vettore 2x2\n",
    "    p0_0<-matrix(c(1,0,0,1),2,2)\n",
    "    #Rumore di processo\n",
    "    Q<-0.01\n",
    "    #Rumore di misura\n",
    "    R<-0.01\n",
    "    X<-NULL\n",
    "    X2<-NULL\n",
    "    pred<-NULL\n",
    "    # Iteriamo per riga sui dati giornalieri\n",
    "    for (i in 0:nrow(all)) {\n",
    "        #paste() Concatena i vettori dopo la conversione in caratteri.\n",
    "        #PREDICTION\n",
    "        namx <- paste(\"x\", i+1,\"_\",i, sep = \"\")\n",
    "        assign(namx,A%*%get(paste(\"x\", i,\"_\",i, sep = \"\")))\n",
    "        \n",
    "        namp <-paste(\"p\", i+1,\"_\",i, sep = \"\")\n",
    "        #assign() Assegna un valore ad una variabile\n",
    "        # %*% è la moltiplicazione di matrici\n",
    "        # t(MATRICE) esegue la trasposta\n",
    "        assign(namp, A%*%(get(paste(\"p\", i,\"_\",i, sep = \"\")))%*%t(A)+Q)\n",
    "\n",
    "        #UPDATE\n",
    "        namE <- paste(\"E\", i+1, sep = \"\")\n",
    "        assign(namE,Y[i+1]-H%*%get(paste(\"x\", i+1,\"_\",i, sep = \"\")))\n",
    "        \n",
    "        namk <- paste(\"k\", i+1, sep = \"\")\n",
    "        assign(namk,get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)%*%(inv(H%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)+R)))\n",
    "\n",
    "        namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n",
    "        assign(namx2,get(paste(\"x\", i+1,\"_\",i, sep = \"\"))+get(paste(\"k\", i+1, sep = \"\"))%*%get(paste(\"E\", i+1, sep = \"\")))\n",
    "        \n",
    "        namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n",
    "        assign(namp2,(p0_0-get(paste(\"k\", i+1, sep = \"\"))%*%H)%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\")))\n",
    "        \n",
    "        #Creo il vettore X appendando i valori predetti 1° riga di x\n",
    "        X<-rbind(X,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[1])  \n",
    "        #Creo il vettore X2 appendando i valori predetti 2° riga di x\n",
    "        X2<-rbind(X2,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[2])\n",
    "        # rimuovo le variabili create 2 step prima\n",
    "        if(i>2){\n",
    "            # remove è usata per rimuovere oggetti creati\n",
    "            remove(list=(paste(\"p\", i-1,\"_\",i-2, sep = \"\")))\n",
    "            remove(list=(paste(\"k\", i-1, sep = \"\")))\n",
    "            remove(list=(paste(\"E\", i-1, sep = \"\")))\n",
    "            remove(list=(paste(\"p\", i-2,\"_\",i-2, sep = \"\")))\n",
    "            remove(list=(paste(\"x\", i-1,\"_\",i-2, sep = \"\")))\n",
    "            remove(list=(paste(\"x\", i-2,\"_\",i-2, sep = \"\")))\n",
    "        }\n",
    "    }\n",
    "    pred<-NULL\n",
    "    # Combino i vettori Y, X ed X2 in una matrice\n",
    "    pred<-cbind(Y,X,round(X2,4))\n",
    "    pred<-as.data.frame(pred)\n",
    "    # appendo il nome della regione\n",
    "    pred$region<-colnames(all[,n+1, drop=FALSE])\n",
    "    # appendo la data\n",
    "    pred$date<-date$date\n",
    "    #Definisco i tassi di crescita o decrescita\n",
    "    pred$actual<-rbind(0,(cbind(pred[2:nrow(pred),1]-pred[1:nrow(pred)-1,1])/pred[1:nrow(pred)-1,1]))*100\n",
    "    pred$predict<-rbind(0,(cbind(pred[2:nrow(pred),2]-pred[1:nrow(pred)-1,2])/pred[1:nrow(pred)-1,2]))*100\n",
    "    pred$pred_rate<-(pred$X/pred$Y-1)*100\n",
    "    pred$X2_change<-rbind(0,(cbind(pred[2:nrow(pred),3]-pred[1:nrow(pred)-1,3])))\n",
    "    pred_all<-rbind(pred_all,pred)\n",
    "}\n",
    "pred_all<-cbind(pred_all[,4:5],pred_all[,1:3])\n",
    "names(pred_all)[5]<-\"X2\"\n",
    "# ordino i valori secondo alla regione e la data\n",
    "pred_all=pred_all[with( pred_all, order(region, date)), ]\n",
    "pred_all<-pred_all[,3:5]\n",
    "\n",
    "write.csv(pred_all,\"/Users/danilogiovannico/Desktop/PROGETTO-Estimation\\ and\\ Data\\ Analysis\\ with\\ Applications/COVID\\ PREDICTIONS/ts_r_KF.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Y              X         X2\n",
      "0         0       0.000000     0.0000\n",
      "1         0       0.000000     0.0000\n",
      "2         0       0.000000     0.0000\n",
      "3         1       0.000000     0.0000\n",
      "4         1       1.271649     0.4847\n",
      "...     ...            ...        ...\n",
      "6505  87385  104916.744681   786.8509\n",
      "6506  88842   83795.558057 -7637.7453\n",
      "6507  90021   82463.952932 -5212.7593\n",
      "6508  90942   86694.638869 -1581.3426\n",
      "6509     32   90420.888198   459.6580\n",
      "\n",
      "[6510 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "p=pd.read_csv(\"./ts_r_KF.csv\", delimiter = ',')\n",
    "print(p)\n",
    "# Uniamo l'output di R a causa di un problema con il pacchetto\n",
    "t=ts_confirmed\n",
    "t=t.stack().reset_index(name='confirmed')\n",
    "t.columns=['date', 'region','confirmed']\n",
    "t['date']=pd.to_datetime(t['date'] ,errors ='coerce')\n",
    "t=t.sort_values(['region', 'date'])\n",
    "\n",
    "# Estraggo le prime 3 colonne\n",
    "temp=t.iloc[:,:3]\n",
    "temp=temp.reset_index(drop=True)\n",
    "for i in range(1,len(t)+1):\n",
    "    #controllo se le regioni sono diverse\n",
    "    if(temp.iloc[i,1] is not temp.iloc[i-1,1]):\n",
    "        # aggiungo la nuova riga\n",
    "        temp.loc[len(temp)+1] = [temp.iloc[i-1,0]+ pd.DateOffset(1),temp.iloc[i-1,1], 0] \n",
    "temp=temp.sort_values(['region', 'date'])\n",
    "p.set_index(temp.index,inplace=True)\n",
    "#temp=temp.reset_index(drop=True)\n",
    "temp['Y']=p['Y']\n",
    "temp['X']=p['X']\n",
    "temp['X2']=p['X2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD THE STRUCTURE OF THE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>Abruzzo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   region  confirmed\n",
       "0 2020-02-24  Abruzzo          0\n",
       "1 2020-02-25  Abruzzo          0\n",
       "2 2020-02-26  Abruzzo          0\n",
       "3 2020-02-27  Abruzzo          1\n",
       "4 2020-02-28  Abruzzo          1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=ts_confirmed\n",
    "t=t.stack().reset_index(name='confirmed')\n",
    "t.columns=['date', 'region','confirmed']\n",
    "t['date']=pd.to_datetime(t['date'] ,errors ='coerce')\n",
    "t=t.sort_values(['region', 'date'])\n",
    "\n",
    "# Aggiungo 1 giorno futuro per la previsione\n",
    "t=t.reset_index(drop=True)\n",
    "for i in range(1,len(t)+1):\n",
    "    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n",
    "        t.loc[len(t)+1] = [t.iloc[i-1,0]+ pd.DateOffset(1),t.iloc[i-1,1], 0] \n",
    "t=t.sort_values(['region', 'date'])\n",
    "t=t.reset_index(drop=True)\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  \n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  \n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "t['1_day_change']=t['3_day_change']=t['7_day_change']=t['1_day_change_rate']=t['3_day_change_rate']=t['7_day_change_rate']=t['last_day']=0\n",
    "for i in range(1,len(t)):\n",
    "    #controllo se la riga attuale è differente dalla precedente per nome regione\n",
    "    if(t.iloc[i,1] is t.iloc[i-2,1]):\n",
    "        # setto il valore di cambiamento ad un giorno come differenza dei confermati alla riga attuale - la precedente\n",
    "        t.iloc[i,3]=t.iloc[i-1,2]-t.iloc[i-2,2]\n",
    "        # setto 1_day_change_rate in modo analogo\n",
    "        t.iloc[i,6]=(t.iloc[i-1,2]/t.iloc[i-2,2]-1)*100\n",
    "        # setto last_day al valore predente dei confermati\n",
    "        t.iloc[i,9]=t.iloc[i-1,2]\n",
    "    # Analogamente setto il cambiamento per i 3 giorni\n",
    "    if(t.iloc[i,1] is t.iloc[i-4,1]):\n",
    "        t.iloc[i,4]=t.iloc[i-1,2]-t.iloc[i-4,2]\n",
    "        t.iloc[i,7]=(t.iloc[i-1,2]/t.iloc[i-4,2]-1)*100\n",
    "    # Analogamente setto il cambiamento per i 7 giorni\n",
    "    if(t.iloc[i,1] is t.iloc[i-8,1]):\n",
    "        t.iloc[i,5]=t.iloc[i-1,2]-t.iloc[i-8,2]\n",
    "        t.iloc[i,8]=(t.iloc[i-1,2]/t.iloc[i-8,2]-1)*100\n",
    "\n",
    "# Setto a zero i valori NaN\n",
    "t=t.fillna(0) \n",
    "# Eseguo il merge con i valori predetti dal filtro di kalman\n",
    "t=t.merge(temp[['date','region', 'X']],how='left',on=['date','region'])\n",
    "t=t.rename(columns = {'X':'kalman_prediction'}) \n",
    "t=t.replace([np.inf, -np.inf], 0)\n",
    "t['kalman_prediction']=round(t['kalman_prediction'])\n",
    "train=t.merge(confirmed_df[['region','population']],how='left',on='region')\n",
    "train=train.rename(columns = {'Population':'population'})\n",
    "# train['population']=train['population'].str.replace(r\" \", '')\n",
    "# train['population']=train['population'].str.replace(r\",\", '')\n",
    "train['population']=train['population'].fillna(1)\n",
    "train['population']=train['population'].astype('int32')\n",
    "train['infected_rate'] =train['last_day']/train['population']*10000\n",
    "#train=train.merge(w,how='left',on=['date','region'])\n",
    "train=train.sort_values(['region', 'date'])\n",
    "### Compiliamo i valori mancanti\n",
    "for i in range(0,len(train)):\n",
    "    if(np.isnan(train.iloc[i,12])):\n",
    "        if(train.iloc[i,1] is train.iloc[i-1,1]):\n",
    "            train.iloc[i,10]=train.iloc[i-1,10]\n",
    "            train.iloc[i,12]=train.iloc[i-1,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONE-DAY PREDICTION VIA KALMAN FILTER WITH PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [region, mse, rmse, mae]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>kalman_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>2020-12-20</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>100089</td>\n",
       "      <td>99172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>101474</td>\n",
       "      <td>101269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>102578</td>\n",
       "      <td>102917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>103326</td>\n",
       "      <td>103984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>104022</td>\n",
       "      <td>104489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>87385</td>\n",
       "      <td>104917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>88842</td>\n",
       "      <td>83796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>90021</td>\n",
       "      <td>82464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>90942</td>\n",
       "      <td>86695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>0</td>\n",
       "      <td>90421.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  region  confirmed  kalman_prediction\n",
       "6500 2020-12-20  Veneto     100089            99172.0\n",
       "6501 2020-12-21  Veneto     101474           101269.0\n",
       "6502 2020-12-22  Veneto     102578           102917.0\n",
       "6503 2020-12-23  Veneto     103326           103984.0\n",
       "6504 2020-12-24  Veneto     104022           104489.0\n",
       "6505 2020-12-25  Veneto      87385           104917.0\n",
       "6506 2020-12-26  Veneto      88842            83796.0\n",
       "6507 2020-12-27  Veneto      90021            82464.0\n",
       "6508 2020-12-28  Veneto      90942            86695.0\n",
       "6509 2020-12-29  Veneto          0            90421.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select region\n",
    "region='Veneto'\n",
    "\n",
    "#Eseguiamo una valutazione sulle metriche MSE, RMSE e MAE sui valori predetti\n",
    "evaluation=pd.DataFrame(columns=['region','mse','rmse','mae'])\n",
    "place=0\n",
    "for i in range(1,len(t)):\n",
    "    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n",
    "        # array valori predetti\n",
    "        ex=np.array(t.iloc[i-len(ts_confirmed):i,10])\n",
    "        # array valori confermati\n",
    "        pred=np.array(t.iloc[i-len(ts_confirmed):i,2])\n",
    "        evaluation=evaluation.append({'region': t.iloc[i-1,1], 'mse': np.power((ex - pred),2).mean(),'rmse':sqrt(mean_squared_error(ex,pred)),'mae': (abs(ex - pred)).mean()}, ignore_index=True)\n",
    "t.head()\n",
    "p=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n",
    "# p=p.rename(columns = {'confirmed':'recoverd'})\n",
    "p.iloc[len(p)-1,2]=None\n",
    "p=p.set_index(['date'])\n",
    "# Plottiamo valori reali e valori con relativa previsione di Kalman\n",
    "p.iloc[:,1:].plot(marker='o',linewidth=1,markersize=2,figsize=(16,8)).set_title('Kalman Prediction - Select Region to Change - {}'.format(p.iloc[0,0]))\n",
    "mplcursors.cursor(hover=True)\n",
    "print(evaluation[evaluation['region']==p.iloc[0,0]])\n",
    "# print(evaluation)\n",
    "p=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n",
    "p.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORRELATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date   region  confirmed  1_day_change  3_day_change  7_day_change  \\\n",
      "0    2020-02-24  Abruzzo          0             0             0             0   \n",
      "1    2020-02-25  Abruzzo          0             0             0             0   \n",
      "2    2020-02-26  Abruzzo          0             0             0             0   \n",
      "3    2020-02-27  Abruzzo          1             0             0             0   \n",
      "4    2020-02-28  Abruzzo          1             1             1             0   \n",
      "...         ...      ...        ...           ...           ...           ...   \n",
      "6505 2020-12-25   Veneto      87385           696          2548          8243   \n",
      "6506 2020-12-26   Veneto      88842        -16637        -15193        -10629   \n",
      "6507 2020-12-27   Veneto      90021          1457        -14484         -8974   \n",
      "6508 2020-12-28   Veneto      90942          1179        -14001        -10068   \n",
      "6509 2020-12-29   Veneto          0           921          3557        -10532   \n",
      "\n",
      "      1_day_change_rate  3_day_change_rate  7_day_change_rate  last_day  \\\n",
      "0              0.000000           0.000000           0.000000         0   \n",
      "1              0.000000           0.000000           0.000000         0   \n",
      "2              0.000000           0.000000           0.000000         0   \n",
      "3              0.000000           0.000000           0.000000         0   \n",
      "4              0.000000           0.000000           0.000000         1   \n",
      "...                 ...                ...                ...       ...   \n",
      "6505           0.673596           2.510988           8.606271    104022   \n",
      "6506         -15.993732         -14.811168         -10.844369     87385   \n",
      "6507           1.667334         -14.017769          -9.174368     88842   \n",
      "6508           1.327075         -13.459653         -10.059047     90021   \n",
      "6509           1.023095           4.070493         -10.379013     90942   \n",
      "\n",
      "      kalman_prediction  population  infected_rate  \n",
      "0                   0.0     1305770       0.000000  \n",
      "1                   0.0     1305770       0.000000  \n",
      "2                   0.0     1305770       0.000000  \n",
      "3                   0.0     1305770       0.000000  \n",
      "4                   1.0     1305770       0.007658  \n",
      "...                 ...         ...            ...  \n",
      "6505           104917.0     4907704     211.956548  \n",
      "6506            83796.0     4907704     178.056786  \n",
      "6507            82464.0     4907704     181.025588  \n",
      "6508            86695.0     4907704     183.427933  \n",
      "6509            90421.0     4907704     185.304574  \n",
      "\n",
      "[6510 rows x 13 columns]\n",
      "Correlation Matrix\n"
     ]
    }
   ],
   "source": [
    "from string import ascii_letters\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"white\")\n",
    "# Compute the correlation matrix\n",
    "corr = train.iloc[:,2:].corr()\n",
    "print(train)\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 8))\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.9, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "print ('Correlation Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-DAY PREDICTION VIA KALMAN FILTER WITH PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "Kalman X Days Ahead Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pracma)\n",
    "library(Metrics)\n",
    "library(readr)\n",
    "library(reshape)\n",
    "all<- read.csv(\"/Users/danilogiovannico/Desktop/PROGETTO-Estimation\\ and\\ Data\\ Analysis\\ with\\ Applications/COVID\\ PREDICTIONS/ts_r.csv\")\n",
    "all$X1<-NULL\n",
    "# Imposto i giorni di previsione\n",
    "for (i in 1:30) { \n",
    "    if( i>1) {\n",
    "        all<-all_new\n",
    "    }\n",
    "    date<-all[,1, drop=FALSE]\n",
    "    #date[nrow(date) + 1,1] <- format(as.Date(all[nrow(all),1])+1)\n",
    "    date<-rbind(date, data.frame(date = format(as.Date(all[nrow(all),1])+1)))\n",
    "    pred_all<-NULL\n",
    "    for (n in 2:ncol(all)-1) {\n",
    "        Y<-ts(data = all[n+1], start = 1, end =nrow(all)+1)  \n",
    "        t<-1\n",
    "        A<-matrix(c(1,0,t,1),2,2)\n",
    "        H<-matrix(c(1,0),1,2)\n",
    "        #Kalman\n",
    "        x0_0<-matrix(c(0,0),2,1)\n",
    "        p0_0<-matrix(c(1,0,0,1),2,2)\n",
    "        Q<-0.01\n",
    "        R<-0.01\n",
    "        X<-NULL\n",
    "        X2<-NULL\n",
    "        pred<-NULL\n",
    "        for (i in 0:nrow(all)) {\n",
    "            #PREDICTION\n",
    "            namx <- paste(\"x\", i+1,\"_\",i, sep = \"\")\n",
    "            assign(namx,A%*%get(paste(\"x\", i,\"_\",i, sep = \"\")))\n",
    "            namp <-paste(\"p\", i+1,\"_\",i, sep = \"\")\n",
    "            assign(namp, A%*%(get(paste(\"p\", i,\"_\",i, sep = \"\")))%*%t(A)+Q)\n",
    "            #UPDATE\n",
    "            namE <- paste(\"E\", i+1, sep = \"\")\n",
    "            assign(namE,Y[i+1]-H%*%get(paste(\"x\", i+1,\"_\",i, sep = \"\")))        \n",
    "            namk <- paste(\"k\", i+1, sep = \"\")\n",
    "            assign(namk,get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)%*%(inv(H%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)+R)))\n",
    "            namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n",
    "            assign(namx2,get(paste(\"x\", i+1,\"_\",i, sep = \"\"))+get(paste(\"k\", i+1, sep = \"\"))%*%get(paste(\"E\", i+1, sep = \"\")))\n",
    "            namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n",
    "            assign(namp2,(p0_0-get(paste(\"k\", i+1, sep = \"\"))%*%H)%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\")))\n",
    "            X<-rbind(X,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[1])\n",
    "            X2<-rbind(X2,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[2])\n",
    "            if(i>2){\n",
    "                remove(list=(paste(\"p\", i-1,\"_\",i-2, sep = \"\")))\n",
    "                remove(list=(paste(\"k\", i-1, sep = \"\")))\n",
    "                remove(list=(paste(\"E\", i-1, sep = \"\")))\n",
    "                remove(list=(paste(\"p\", i-2,\"_\",i-2, sep = \"\")))\n",
    "                remove(list=(paste(\"x\", i-1,\"_\",i-2, sep = \"\")))\n",
    "                remove(list=(paste(\"x\", i-2,\"_\",i-2, sep = \"\")))}\n",
    "        } \n",
    "        pred<-NULL\n",
    "        pred<-cbind(Y,X,round(X2,4))\n",
    "        pred<-as.data.frame(pred)\n",
    "        pred$region<-colnames(all[,n+1, drop=FALSE])\n",
    "        pred$date<-date$date\n",
    "        pred$actual<-rbind(0,(cbind(pred[2:nrow(pred),1]-pred[1:nrow(pred)-1,1])/pred[1:nrow(pred)-1,1]))*100\n",
    "        pred$predict<-rbind(0,(cbind(pred[2:nrow(pred),2]-pred[1:nrow(pred)-1,2])/pred[1:nrow(pred)-1,2]))*100\n",
    "        pred$pred_rate<-(pred$X/pred$Y-1)*100\n",
    "        pred$X2_change<-rbind(0,(cbind(pred[2:nrow(pred),3]-pred[1:nrow(pred)-1,3])))\n",
    "        pred_all<-rbind(pred_all,pred)\n",
    "    }\n",
    "    pred_all<-cbind(pred_all[,4:5],pred_all[,1:3])\n",
    "    names(pred_all)[5]<-\"X2\"\n",
    "    pred_all<-pred_all[,1:5]    \n",
    "    pred_all_today=pred_all[with( pred_all, order(region, date)), ]\n",
    "    all_new=all\n",
    "    #all_new[nrow(all_new),1]<-all_new[nrow(all),1]+1\n",
    "    # iteriamo modificando la data per la previsione\n",
    "    temp<-with(pred_all_today, pred_all_today[date == format(as.Date(all[nrow(all),1,])+1), ])\n",
    "    temp<-cbind(temp[,1:2],temp[,4])\n",
    "    temp2<-reshape(temp, direction = \"wide\", idvar = \"date\", timevar = \"region\")\n",
    "    # runif fornisce informazioni sulla distribuzione uniforme sull'intervallo da min a max\n",
    "    rand_num<-runif(ncol(temp2)-1, 0.9, 1.05)\n",
    "    temp2[,2:ncol(temp2)]<-temp2[,2:ncol(temp2)]*rand_num\n",
    "    colnames(temp2)=colnames(all_new)\n",
    "    all_new<-rbind(all_new,temp2)\n",
    "    all_new[,2:ncol(all_new)]<-round(all_new[,2:ncol(all_new)])\n",
    "    for (i in 2:ncol(all_new)) {\n",
    "        #Assegno il valore massimo tra il valore al tempo t e quello a t-1\n",
    "        all_new[nrow(all_new),i]=max(all_new[nrow(all_new)-1,i],all_new[nrow(all_new),i])\n",
    "    }\n",
    "}\n",
    "write.csv(all_new,\"/Users/danilogiovannico/Desktop/PROGETTO-Estimation\\ and\\ Data\\ Analysis\\ with\\ Applications/COVID\\ PREDICTIONS/ts_r_KF_ahead.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new=pd.read_csv(\"./ts_r_KF_ahead.csv\", delimiter = ',')\n",
    "all_new['date']=pd.to_datetime(all_new['date'])\n",
    "all_new.tail(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select region\n",
    "region = ['date', region]\n",
    "p_kalman=all_new[region]\n",
    "\n",
    "#p=all_new\n",
    "#p.iloc[len(p)-1,2]=None\n",
    "p_kalman=p_kalman.set_index(['date'])\n",
    "p_kalman.iloc[:,:].plot(marker='o',linewidth=1,markersize=3,figsize=(24,14)).set_title('Kalman Prediction {}'.format(region[1]), fontdict={'fontsize': 22})\n",
    "mplcursors.cursor(hover=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_one_month = p_kalman.tail(30)\n",
    "prediction_two_weeks = prediction_one_month.head(15)\n",
    "prediction_one_month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPREAD PREDICTION WITH ROBUST APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(pracma)\n",
    "library(Metrics)\n",
    "library(readr)\n",
    "library(matrixStats)\n",
    "all<- read.csv(\"/Users/danilogiovannico/Desktop/PROGETTO-Estimation\\ and\\ Data\\ Analysis\\ with\\ Applications/COVID\\ PREDICTIONS/ts_r.csv\")\n",
    "all$X1<-NULL\n",
    "date<-all[,1, drop=FALSE]\n",
    "# La funzione rbind () combina vettori, matrici o frame di dati per righe\n",
    "date<-rbind(date, data.frame(date = format(as.Date(all[nrow(all),1])+1)))\n",
    "#date[nrow(date) + 1,1] <- as.Date(all[nrow(all),1])+1\n",
    "pred_all<-NULL\n",
    "# ncol ritorna il numero di colonne presenti nel dataset, nrow il numero di righe\n",
    "# Iteriamo per colonna sulle regioni\n",
    "for (n in 2:ncol(all)-1) {\n",
    "    # Costruisco la time series\n",
    "    #La funzione ts () convertirà un vettore numerico in un oggetto della serie temporale R. \n",
    "    #Il formato è ts (vector, start=, end=, frequency=) dove inizio e fine sono i tempi della prima e dell'ultima osservazione e la frequenza è \n",
    "    #il numero di osservazioni per unità di tempo (1 = annuale, 4 = trimestrale, 12 = mensile, ecc.).\n",
    "    Y<-ts(data = all[n+1], start = 1, end =nrow(all)+1) \n",
    "    # Time Step\n",
    "    t<-1\n",
    "    # Costruiamo la matrice A 2x2\n",
    "    A<-matrix(c(1,0,t,1),2,2)\n",
    "    #Matrice di osservazione\n",
    "    H<-matrix(c(1,0),1,2)\n",
    "    # Condizioni iniziali filtro di Kalman\n",
    "    # Vettore di stato 2x1\n",
    "    x0_0<-matrix(c(0,0),2,1)\n",
    "    # Vettore 2x2\n",
    "    p0_0<-matrix(c(1,0,0,1),2,2)\n",
    "    #Rumore di processo\n",
    "    Q<-matrix(c(0.01,0.01,0.01,0.01),2,2)\n",
    "    #Rumore di misura\n",
    "    R<-matrix(c(0.01),1,1)\n",
    "    X<-NULL\n",
    "    X2<-NULL\n",
    "    pred<-NULL\n",
    "    \n",
    "    N<-30\n",
    "    SMALL<-1e-10\n",
    "    SMALL_LEL<-1e-9*diag(length(x0_0))\n",
    "    residual_vec <- vector()\n",
    "    residual_j_vec <- vector()\n",
    "    residual_j_log_vec <- vector()\n",
    "    normHessian_vec <- vector()\n",
    "    normHRH=norm(t(H)%*%inv(R)%*%H)\n",
    "    alpha=normHRH\n",
    "    # Iteriamo per riga sui dati giornalieri\n",
    "    for (i in 0:nrow(all)) {\n",
    "        summ_rj<-0\n",
    "        summ_log_rj<-0\n",
    "        \n",
    "        namx <- paste(\"x\", i+1,\"_\",i, sep = \"\")\n",
    "        assign(namx,A%*%get(paste(\"x\", i,\"_\",i, sep = \"\")))\n",
    "        \n",
    "        namp <-paste(\"p\", i+1,\"_\",i, sep = \"\")\n",
    "        assign(namp, A%*%(get(paste(\"p\", i,\"_\",i, sep = \"\")))%*%t(A)+Q)\n",
    "        \n",
    "        ppred = (1/2)*(t(get(namp)) + get(namp))\n",
    "        \n",
    "        r<-drop(Y[i+1]-H%*%get(paste(\"x\", i,\"_\",i, sep = \"\")))\n",
    "        r2<-drop(t(Y[i+1]-H%*%get(paste(\"x\", i,\"_\",i, sep = \"\"))) %*% (Y[i+1]-H%*%get(paste(\"x\", i,\"_\",i, sep = \"\"))))\n",
    "        \n",
    "        if(r2<SMALL){\n",
    "            r2=SMALL\n",
    "        }\n",
    "        if(i>1){\n",
    "            if(residual_vec[i-1]<SMALL) {\n",
    "                residual_vec[i-1]=SMALL\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        residual_vec <- c(residual_vec, r2)\n",
    "        \n",
    "        if(i>255) {\n",
    "            \n",
    "            residual_j_vec <- residual_vec[(i-N+1):i]\n",
    "            j<-which(residual_j_vec==max(residual_j_vec))\n",
    "            residual_j_vec[j] = residual_j_vec[j]*1000\n",
    "            #REGULARIZATION\n",
    "            sc<-100\n",
    "            r2max<-residual_j_vec[j]\n",
    "            if(r2>r2max){\n",
    "                r2Reg<-r2*sc\n",
    "                r2<-r2Reg\n",
    "            }else{\n",
    "                r2Reg<-r2max*sc\n",
    "            }\n",
    "\n",
    "            residual_j_log_vec<-residual_j_vec\n",
    "            for (q in 0:length(residual_j_log_vec)) {\n",
    "                residual_j_log_vec[q]<-residual_j_log_vec[q]*log(residual_j_log_vec[q])\n",
    "            }\n",
    "            \n",
    "            Dk<-sum(residual_j_vec) + (sc-1)*r2Reg\n",
    "            Sk<-sum(residual_j_log_vec) + sc*r2max*log(sc)+(sc-1)*r2Reg*log(r2Reg)\n",
    "            if(is.nan(Dk)) {\n",
    "                print('Dk NAN')\n",
    "            }\n",
    "            if(is.nan(Sk)) {\n",
    "                print('Sk NAN')\n",
    "            }\n",
    "            \n",
    "            #Calculate functional cost C\n",
    "            C = (-1/log(i))*(Sk/Dk - log(Dk))\n",
    "            #Calculate gradient\n",
    "            if(1/Dk**2<SMALL){\n",
    "                invDkReg2 <- 1/(Dk**2 + SMALL)\n",
    "            } else {\n",
    "                invDkReg2 <- 1/Dk**2\n",
    "            }\n",
    "            gradH<-((invDkReg2*(2/log(i))) * (Dk*log(r2)-Sk)) %*% (r*H)\n",
    "            \n",
    "            #Calculate Hessian\n",
    "            hessianH<-(invDkReg2*(2*log(i))) * ((2*t(r*H)%*%(r*H) * (2*log(r2)-2*Sk/Dk -Dk/r2 +1)) - t(H)%*%H*(Dk*log(r2)-Sk))\n",
    "            \n",
    "            #Compute alpha\n",
    "            if(length(normHessian_vec)<10){\n",
    "                normHessian_vec <- c(normHessian_vec, norm(hessianH))\n",
    "            }\n",
    "            lambda_val<-eigen(hessianH)\n",
    "            alpha<-normHRH/median(normHessian_vec)\n",
    "           \n",
    "            if(is.infinite(alpha))\n",
    "            {\n",
    "                alpha=normHRH\n",
    "            }\n",
    "            alpha = alpha/2\n",
    "            if(min(lambda_val$values)<0) {\n",
    "                namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n",
    "                assign(namx2,get(namx))\n",
    "\n",
    "                namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n",
    "                assign(namp2,get(namp))\n",
    "            } else {\n",
    "\n",
    "                namk <- paste(\"k\", i+1, sep = \"\")\n",
    "                assign(namk,inv(inv(ppred) + alpha*(hessianH+SMALL_LEL)) * alpha*(hessianH))\n",
    "                \n",
    "                namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n",
    "                assign(namp2,inv(inv(ppred) + alpha*hessianH+SMALL_LEL))\n",
    "                \n",
    "                namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n",
    "                assign(namx2,get(paste(\"x\", i+1,\"_\",i, sep = \"\")) + get(namk)%*%(get(paste(\"x\", i,\"_\",i, sep = \"\"))-get(paste(\"x\", i+1,\"_\",i, sep = \"\"))) - alpha*get(namp2)%*%t(gradH))\n",
    "            }\n",
    "            \n",
    "        } else {\n",
    "            #UPDATE\n",
    "            namR <- paste(\"R\", i+1, sep = \"\")\n",
    "            assign(namR,Y[i+1]-H%*%get(paste(\"x\", i+1,\"_\",i, sep = \"\")))\n",
    "\n",
    "            namk <- paste(\"k\", i+1, sep = \"\")\n",
    "            assign(namk,get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H)%*%(inv(H%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\"))%*%t(H) + R)))\n",
    "\n",
    "            namx2 <- paste(\"x\", i+1,\"_\",i+1, sep = \"\")\n",
    "            assign(namx2,get(paste(\"x\", i+1,\"_\",i, sep = \"\"))+get(paste(\"k\", i+1, sep = \"\"))%*%get(paste(\"R\", i+1, sep = \"\")))\n",
    "\n",
    "            namp2 <- paste(\"p\", i+1,\"_\",i+1, sep = \"\")\n",
    "            assign(namp2,(p0_0-get(paste(\"k\", i+1, sep = \"\"))%*%H)%*%get(paste(\"p\", i+1,\"_\",i, sep = \"\")))\n",
    "        }\n",
    "\n",
    "        #Creo il vettore X appendando i valori predetti 1° riga di x\n",
    "        X<-rbind(X,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[1])  \n",
    "        #Creo il vettore X2 appendando i valori predetti 2° riga di x\n",
    "        X2<-rbind(X2,get(paste(\"x\", i+1,\"_\",i,sep = \"\"))[2])\n",
    "        # rimuovo le variabili create 2 step prima\n",
    "        if(i>2){\n",
    "            # remove è usata per rimuovere oggetti creati\n",
    "            remove(list=(paste(\"p\", i-1,\"_\",i-2, sep = \"\")))\n",
    "            remove(list=(paste(\"k\", i-1, sep = \"\")))\n",
    "            remove(list=(paste(\"R\", i-1, sep = \"\")))\n",
    "            remove(list=(paste(\"p\", i-2,\"_\",i-2, sep = \"\")))\n",
    "            remove(list=(paste(\"x\", i-1,\"_\",i-2, sep = \"\")))\n",
    "            remove(list=(paste(\"x\", i-2,\"_\",i-2, sep = \"\")))\n",
    "        }\n",
    "    }\n",
    "    pred<-NULL\n",
    "    # Combino i vettori Y, X ed X2 in una matrice\n",
    "    pred<-cbind(Y,X,round(X2,4))\n",
    "    pred<-as.data.frame(pred)\n",
    "    # appendo il nome della regione\n",
    "    pred$region<-colnames(all[,n+1, drop=FALSE])\n",
    "    # appendo la data\n",
    "    pred$date<-date$date\n",
    "    #Definisco i tassi di crescita o decrescita\n",
    "    pred$actual<-rbind(0,(cbind(pred[2:nrow(pred),1]-pred[1:nrow(pred)-1,1])/pred[1:nrow(pred)-1,1]))*100\n",
    "    pred$predict<-rbind(0,(cbind(pred[2:nrow(pred),2]-pred[1:nrow(pred)-1,2])/pred[1:nrow(pred)-1,2]))*100\n",
    "    pred$pred_rate<-(pred$X/pred$Y-1)*100\n",
    "    pred$X2_change<-rbind(0,(cbind(pred[2:nrow(pred),3]-pred[1:nrow(pred)-1,3])))\n",
    "    pred_all<-rbind(pred_all,pred)\n",
    "}\n",
    "pred_all<-cbind(pred_all[,4:5],pred_all[,1:3])\n",
    "names(pred_all)[5]<-\"X2\"\n",
    "# ordino i valori secondo alla regione e la data\n",
    "pred_all=pred_all[with( pred_all, order(region, date)), ]\n",
    "pred_all<-pred_all[,3:5]\n",
    "\n",
    "write.csv(pred_all,\"/Users/danilogiovannico/Desktop/PROGETTO-Estimation\\ and\\ Data\\ Analysis\\ with\\ Applications/COVID\\ PREDICTIONS/ts_r_KF.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Y              X        X2\n",
      "0         0       0.000000    0.0000\n",
      "1         0       0.000000    0.0000\n",
      "2         0       0.000000    0.0000\n",
      "3         1       0.000000    0.0000\n",
      "4         1       1.271649    0.4847\n",
      "...     ...            ...       ...\n",
      "6505  87385  104282.870714  132.3302\n",
      "6506  88842  104198.571470   84.0057\n",
      "6507  90021  104046.285331   32.4733\n",
      "6508  90942  103841.246786  -17.4076\n",
      "6509     32  103596.038781  -63.7591\n",
      "\n",
      "[6510 rows x 3 columns]\n",
      "           date   region  confirmed      Y              X        X2\n",
      "0    2020-02-24  Abruzzo          0      0       0.000000    0.0000\n",
      "1    2020-02-25  Abruzzo          0      0       0.000000    0.0000\n",
      "2    2020-02-26  Abruzzo          0      0       0.000000    0.0000\n",
      "3    2020-02-27  Abruzzo          1      1       0.000000    0.0000\n",
      "4    2020-02-28  Abruzzo          1      1       1.271649    0.4847\n",
      "...         ...      ...        ...    ...            ...       ...\n",
      "6485 2020-12-25   Veneto      87385  87385  104282.870714  132.3302\n",
      "6486 2020-12-26   Veneto      88842  88842  104198.571470   84.0057\n",
      "6487 2020-12-27   Veneto      90021  90021  104046.285331   32.4733\n",
      "6488 2020-12-28   Veneto      90942  90942  103841.246786  -17.4076\n",
      "6510 2020-12-29   Veneto          0     32  103596.038781  -63.7591\n",
      "\n",
      "[6510 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "p=pd.read_csv(\"./ts_r_KF.csv\", delimiter = ',')\n",
    "print(p)\n",
    "# Uniamo l'output di R a causa di un problema con il pacchetto\n",
    "t=ts_confirmed\n",
    "t=t.stack().reset_index(name='confirmed')\n",
    "t.columns=['date', 'region','confirmed']\n",
    "t['date']=pd.to_datetime(t['date'] ,errors ='coerce')\n",
    "t=t.sort_values(['region', 'date'])\n",
    "\n",
    "# Estraggo le prime 3 colonne\n",
    "temp=t.iloc[:,:3]\n",
    "temp=temp.reset_index(drop=True)\n",
    "for i in range(1,len(t)+1):\n",
    "    #controllo se le regioni sono diverse\n",
    "    if(temp.iloc[i,1] is not temp.iloc[i-1,1]):\n",
    "        # aggiungo la nuova riga\n",
    "        temp.loc[len(temp)+1] = [temp.iloc[i-1,0]+ pd.DateOffset(1),temp.iloc[i-1,1], 0] \n",
    "temp=temp.sort_values(['region', 'date'])\n",
    "p.set_index(temp.index,inplace=True)\n",
    "#temp=temp.reset_index(drop=True)\n",
    "temp['Y']=p['Y']\n",
    "temp['X']=p['X']\n",
    "temp['X2']=p['X2']\n",
    "print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/Users/danilogiovannico/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "t=ts_confirmed\n",
    "t=t.stack().reset_index(name='confirmed')\n",
    "t.columns=['date', 'region','confirmed']\n",
    "t['date']=pd.to_datetime(t['date'] ,errors ='coerce')\n",
    "t=t.sort_values(['region', 'date'])\n",
    "\n",
    "# Aggiungo 1 giorno futuro per la previsione\n",
    "t=t.reset_index(drop=True)\n",
    "for i in range(1,len(t)+1):\n",
    "    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n",
    "        t.loc[len(t)+1] = [t.iloc[i-1,0]+ pd.DateOffset(1),t.iloc[i-1,1], 0] \n",
    "t=t.sort_values(['region', 'date'])\n",
    "t=t.reset_index(drop=True)\n",
    "t.head()\n",
    "\n",
    "t['1_day_change']=t['3_day_change']=t['7_day_change']=t['1_day_change_rate']=t['3_day_change_rate']=t['7_day_change_rate']=t['last_day']=0\n",
    "for i in range(1,len(t)):\n",
    "    #controllo se la riga attuale è differente dalla precedente per nome regione\n",
    "    if(t.iloc[i,1] is t.iloc[i-2,1]):\n",
    "        # setto il valore di cambiamento ad un giorno come differenza dei confermati alla riga attuale - la precedente\n",
    "        t.iloc[i,3]=t.iloc[i-1,2]-t.iloc[i-2,2]\n",
    "        # setto 1_day_change_rate in modo analogo\n",
    "        t.iloc[i,6]=(t.iloc[i-1,2]/t.iloc[i-2,2]-1)*100\n",
    "        # setto last_day al valore predente dei confermati\n",
    "        t.iloc[i,9]=t.iloc[i-1,2]\n",
    "    # Analogamente setto il cambiamento per i 3 giorni\n",
    "    if(t.iloc[i,1] is t.iloc[i-4,1]):\n",
    "        t.iloc[i,4]=t.iloc[i-1,2]-t.iloc[i-4,2]\n",
    "        t.iloc[i,7]=(t.iloc[i-1,2]/t.iloc[i-4,2]-1)*100\n",
    "    # Analogamente setto il cambiamento per i 7 giorni\n",
    "    if(t.iloc[i,1] is t.iloc[i-8,1]):\n",
    "        t.iloc[i,5]=t.iloc[i-1,2]-t.iloc[i-8,2]\n",
    "        t.iloc[i,8]=(t.iloc[i-1,2]/t.iloc[i-8,2]-1)*100\n",
    "\n",
    "# Setto a zero i valori NaN\n",
    "t=t.fillna(0) \n",
    "# Eseguo il merge con i valori predetti dal filtro di kalman\n",
    "t=t.merge(temp[['date','region', 'X']],how='left',on=['date','region'])\n",
    "t=t.rename(columns = {'X':'kalman_prediction'}) \n",
    "t=t.replace([np.inf, -np.inf], 0)\n",
    "t['kalman_prediction']=round(t['kalman_prediction'])\n",
    "train=t.merge(confirmed_df[['region','population']],how='left',on='region')\n",
    "train=train.rename(columns = {'Population':'population'})\n",
    "# train['population']=train['population'].str.replace(r\" \", '')\n",
    "# train['population']=train['population'].str.replace(r\",\", '')\n",
    "train['population']=train['population'].fillna(1)\n",
    "train['population']=train['population'].astype('int32')\n",
    "train['infected_rate'] =train['last_day']/train['population']*10000\n",
    "#train=train.merge(w,how='left',on=['date','region'])\n",
    "train=train.sort_values(['region', 'date'])\n",
    "### Compiliamo i valori mancanti\n",
    "for i in range(0,len(train)):\n",
    "    if(np.isnan(train.iloc[i,12])):\n",
    "        if(train.iloc[i,1] is train.iloc[i-1,1]):\n",
    "            train.iloc[i,10]=train.iloc[i-1,10]\n",
    "            train.iloc[i,12]=train.iloc[i-1,12]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [region, mse, rmse, mae]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>kalman_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>2020-12-20</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>100089</td>\n",
       "      <td>103708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6501</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>101474</td>\n",
       "      <td>103804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>102578</td>\n",
       "      <td>103911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>2020-12-23</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>103326</td>\n",
       "      <td>104027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>104022</td>\n",
       "      <td>104150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>87385</td>\n",
       "      <td>104283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>2020-12-26</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>88842</td>\n",
       "      <td>104199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>90021</td>\n",
       "      <td>104046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>90942</td>\n",
       "      <td>103841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>0</td>\n",
       "      <td>103596.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  region  confirmed  kalman_prediction\n",
       "6500 2020-12-20  Veneto     100089           103708.0\n",
       "6501 2020-12-21  Veneto     101474           103804.0\n",
       "6502 2020-12-22  Veneto     102578           103911.0\n",
       "6503 2020-12-23  Veneto     103326           104027.0\n",
       "6504 2020-12-24  Veneto     104022           104150.0\n",
       "6505 2020-12-25  Veneto      87385           104283.0\n",
       "6506 2020-12-26  Veneto      88842           104199.0\n",
       "6507 2020-12-27  Veneto      90021           104046.0\n",
       "6508 2020-12-28  Veneto      90942           103841.0\n",
       "6509 2020-12-29  Veneto          0           103596.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select region\n",
    "region='Veneto'\n",
    "\n",
    "#Eseguiamo una valutazione sulle metriche MSE, RMSE e MAE sui valori predetti\n",
    "evaluation=pd.DataFrame(columns=['region','mse','rmse','mae'])\n",
    "place=0\n",
    "for i in range(1,len(t)):\n",
    "    if(t.iloc[i,1] is not t.iloc[i-1,1]):\n",
    "        # array valori predetti\n",
    "        ex=np.array(t.iloc[i-len(ts_confirmed):i,10])\n",
    "        # array valori confermati\n",
    "        pred=np.array(t.iloc[i-len(ts_confirmed):i,2])\n",
    "        evaluation=evaluation.append({'region': t.iloc[i-1,1], 'mse': np.power((ex - pred),2).mean(),'rmse':sqrt(mean_squared_error(ex,pred)),'mae': (abs(ex - pred)).mean()}, ignore_index=True)\n",
    "t.head()\n",
    "p=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n",
    "# p=p.rename(columns = {'confirmed':'recoverd'})\n",
    "p.iloc[len(p)-1,2]=None\n",
    "p=p.set_index(['date'])\n",
    "# Plottiamo valori reali e valori con relativa previsione di Kalman\n",
    "p.iloc[:,1:].plot(marker='o',linewidth=1,markersize=2,figsize=(16,8)).set_title('Kalman Prediction - Select Region to Change - {}'.format(p.iloc[0,0]))\n",
    "mplcursors.cursor(hover=True)\n",
    "print(evaluation[evaluation['region']==p.iloc[0,0]])\n",
    "# print(evaluation)\n",
    "p=t[t['region']==region][['date','region','confirmed','kalman_prediction']]\n",
    "p.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIRD MODEL + EKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>stato</th>\n",
       "      <th>denominazione_regione</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>totale_positivi</th>\n",
       "      <th>totale_casi</th>\n",
       "      <th>deceduti</th>\n",
       "      <th>dimessi_guariti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>2020-12-24T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>104022</td>\n",
       "      <td>229782</td>\n",
       "      <td>5859</td>\n",
       "      <td>119901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6425</th>\n",
       "      <td>2020-12-25T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>87385</td>\n",
       "      <td>234792</td>\n",
       "      <td>5953</td>\n",
       "      <td>141454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>2020-12-26T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>88842</td>\n",
       "      <td>237315</td>\n",
       "      <td>5986</td>\n",
       "      <td>142487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>2020-12-27T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>90021</td>\n",
       "      <td>240652</td>\n",
       "      <td>6038</td>\n",
       "      <td>144593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>2020-12-28T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>90942</td>\n",
       "      <td>243434</td>\n",
       "      <td>6107</td>\n",
       "      <td>146385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     data stato denominazione_regione        lat       long  \\\n",
       "6404  2020-12-24T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "6425  2020-12-25T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "6446  2020-12-26T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "6467  2020-12-27T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "6488  2020-12-28T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "\n",
       "      totale_positivi  totale_casi  deceduti  dimessi_guariti  \n",
       "6404           104022       229782      5859           119901  \n",
       "6425            87385       234792      5953           141454  \n",
       "6446            88842       237315      5986           142487  \n",
       "6467            90021       240652      6038           144593  \n",
       "6488            90942       243434      6107           146385  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "data = None\n",
    "data_SIR = cleared_dataframe.sort_values([\"denominazione_regione\", \"data\"], ascending = (True, True))\n",
    "data_SIR.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIRDEKF(Q, R, x0, P0, y, DAYS_PREDICTION):\n",
    "    T   = y[:, 0].size       # observation horizon  \n",
    "    x_post = np.zeros((T+DAYS_PREDICTION, 7))   # corrected estimations time series    \n",
    "    \n",
    "    # initializations\n",
    "    x_prior = x0                # initial estimate\n",
    "    P_prior  = P0                 # initial estimate covariance\n",
    "    \n",
    "    # output Jacobian C = dh / dx\n",
    "    C   = np.array([[1, 0, 0, 0, 0, 0, 0],                        \n",
    "                    [0, 1, 0, 0, 0, 0, 0], \n",
    "                    [0, 0, 1, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 1, 0, 0, 0]])                        \n",
    "                       \n",
    "    for t in range(1, T+DAYS_PREDICTION):\n",
    "        if t < T:\n",
    "            # correction step\n",
    "            y_est   = y[t, :] - np.dot(C, x_prior)                           # innovation\n",
    "            S   = np.dot(C, np.dot(P_prior, C.transpose())) + R              # innovation covariance\n",
    "            K   = np.dot(P_prior, np.dot(C.transpose(), np.linalg.inv(S)))   # correction gain\n",
    "\n",
    "            x_post[t] = x_prior + np.dot(K, y_est)                           # corrected estimate\n",
    "            P_post = (np.identity(x0.size) - np.dot(K, C)).dot(P_prior)      # corrected estimate covariance\n",
    "\n",
    "            # prediction step\n",
    "            # state Jacobian A = df / dx\n",
    "            A   = np.array([[1 - x_post[t, 1] / N * x_post[t, 4],                           - x_post[t, 0] / N * x_post[t, 4], 0, 0, - x_post[t, 0] * x_post[t, 1] / N,           0,           0],                        \n",
    "                            [    x_post[t, 1] / N * x_post[t, 4], 1 + x_post[t, 0] / N * x_post[t, 4] - x_post[t, 5] - x_post[t, 6], 0, 0,   x_post[t, 0] * x_post[t, 1] / N, - x_post[t, 1], - x_post[t, 1]], \n",
    "                            [                            0,                                             x_post[t, 5], 1, 0,                           0,   x_post[t, 1],           0],\n",
    "                            [                            0,                                             x_post[t, 6], 0, 1,                           0,           0,   x_post[t, 1]],\n",
    "                            [                            0,                                                     0, 0, 0,                           1,           0,           0],\n",
    "                            [                            0,                                                     0, 0, 0,                           0,           1,           0],\n",
    "                            [                            0,                                                     0, 0, 0,                           0,           0,           1]])\n",
    "\n",
    "            # non linear dynamic of the SIRD model \n",
    "            hSp = - x_post[t, 0] * x_post[t, 1] / N * x_post[t, 4]\n",
    "            hIp =   x_post[t, 0] * x_post[t, 1] / N * x_post[t, 4] - x_post[t, 1] * x_post[t, 5] - x_post[t, 1] * x_post[t, 6]\n",
    "            hRp =   x_post[t, 1] * x_post[t, 5]\n",
    "            hDp =   x_post[t, 1] * x_post[t, 6]\n",
    "\n",
    "            x_prior =  x_post[t] + np.array([hSp, hIp, hRp, hDp, 0, 0, 0])  # predicted estimate x_prior = f(x_post)\n",
    "            P_prior =  np.dot(A, np.dot(P_post, A.transpose())) + Q         # predicted estimate covariance  \n",
    "        else:\n",
    "            x_post[t] = x_prior                          # corrected estimate\n",
    "            P_post = P_prior                             # corrected estimate covariance\n",
    "            \n",
    "            # prediction step\n",
    "            # state Jacobian A = df / dx\n",
    "            A   = np.array([[1 - x_post[t, 1] / N * x_post[t, 4],                           - x_post[t, 0] / N * x_post[t, 4], 0, 0, - x_post[t, 0] * x_post[t, 1] / N,           0,           0],                        \n",
    "                            [    x_post[t, 1] / N * x_post[t, 4], 1 + x_post[t, 0] / N * x_post[t, 4] - x_post[t, 5] - x_post[t, 6], 0, 0,   x_post[t, 0] * x_post[t, 1] / N, - x_post[t, 1], - x_post[t, 1]], \n",
    "                            [                            0,                                             x_post[t, 5], 1, 0,                           0,   x_post[t, 1],           0],\n",
    "                            [                            0,                                             x_post[t, 6], 0, 1,                           0,           0,   x_post[t, 1]],\n",
    "                            [                            0,                                                     0, 0, 0,                           1,           0,           0],\n",
    "                            [                            0,                                                     0, 0, 0,                           0,           1,           0],\n",
    "                            [                            0,                                                     0, 0, 0,                           0,           0,           1]])\n",
    "\n",
    "            # non linear dynamic of the SIRD model \n",
    "            hSp = - x_post[t, 0] * x_post[t, 1] / N * x_post[t, 4]\n",
    "            hIp =   x_post[t, 0] * x_post[t, 1] / N * x_post[t, 4] - x_post[t, 1] * x_post[t, 5] - x_post[t, 1] * x_post[t, 6]\n",
    "            hRp =   x_post[t, 1] * x_post[t, 5]\n",
    "            hDp =   x_post[t, 1] * x_post[t, 6]\n",
    "\n",
    "            x_prior =  x_post[t] + np.array([hSp, hIp, hRp, hDp, 0, 0, 0])  # predicted estimate x_prior = f(x_post)\n",
    "            P_prior =  np.dot(A, np.dot(P_post, A.transpose())) + Q         # predicted estimate covariance  \n",
    "                                                                  \n",
    "    return x_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadcost(y, hy): \n",
    "    T = y[:,0].size     \n",
    "    cost = 0\n",
    "\n",
    "    for t in range(1,T):\n",
    "        error = y[t] - hy[t]     \n",
    "        cost  += np.power(np.linalg.norm(error), 2)\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.0012189730307774792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe9bba3da10>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = \"Puglia\"\n",
    "data_filtered = data_SIR[data_SIR['denominazione_regione']==region]\n",
    "# DATASET\n",
    "POPULATIONS = {\n",
    "    #\"Abruzzo\":   1305770,\n",
    "    #\"Basilicata\": 556934,\n",
    "    #\"Calabria\": 1924701,\n",
    "    #\"Campania\": 5785861,\n",
    "    #\"Emilia-Romagna\": 4467118,\n",
    "    #\"Friuli Venezia Giulia\": 1211357,\n",
    "    #\"Lazio\": 5865544,\n",
    "    #\"Liguria\": 1543127,\n",
    "    #\"Lombardia\": 10103969,\n",
    "    #\"Marche\": 1518400,\n",
    "    #\"Molise\": 302265,\n",
    "    #\"P.A. Bolzano\": 106951,\n",
    "    #\"P.A. Trento\": 117417,\n",
    "    #\"Piemonte\": 4341375,\n",
    "    \"Puglia\": 4008296,\n",
    "    #\"Sardegna\": 1630474,\n",
    "    #\"Sicilia\": 4968410,\n",
    "    #\"Toscana\": 3722729,\n",
    "    #\"Umbria\": 880285,\n",
    "    #\"Valle d'Aosta\": 125501,\n",
    "    #\"Veneto\": 4907704\n",
    "}\n",
    "\n",
    "# observed infected \n",
    "oI = data_filtered['totale_casi'].values \n",
    "\n",
    "# observed recovered\n",
    "oR = data_filtered['dimessi_guariti'].values \n",
    "\n",
    "# observed dead\n",
    "oD = data_filtered['deceduti'].values    \n",
    "                   \n",
    "# observed susceptibles \n",
    "N = POPULATIONS[region]  # population size\n",
    "T = oI.size       # observation horizon\n",
    "DAYS_PREDICTION = 5\n",
    "\n",
    "oS = np.zeros((T,))\n",
    "for t in range(0, T):\n",
    "    oS[t] = N - (oI[t] + oR[t] + oD[t])  \n",
    "    \n",
    "y  = np.transpose(np.array([     oS,      oI,      oR,      oD]))\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "# initializazions \n",
    "thetaKF = np.zeros((T, 3))\n",
    "x0     = np.concatenate([y[0], thetaKF[0]])\n",
    "P0      = np.identity(x0.size)\n",
    "\n",
    "mu, sigma, sigma2 = 0, 0.1, 0.001 # mean and standard deviation\n",
    "\n",
    "Q       = np.identity(x0.size) * np.random.normal(mu, sigma, x0.size)\n",
    "R       = np.identity(y[0, :].size) * np.random.normal(mu, sigma2, y[0, :].size)\n",
    "\n",
    "# state estimation \n",
    "x      = SIRDEKF(Q, R, x0, P0, y, DAYS_PREDICTION)\n",
    "\n",
    "# parameter estimate\n",
    "thetaKF = x[:, 4:]\n",
    "print(\"MSE = \", quadcost(y, x[0:T:, 0:4]))   # mean squared error between the observed\n",
    "##############################################################################\n",
    "\n",
    "# PLOTS\n",
    "fig, axs = plt.subplots(1, 1, constrained_layout=True)\n",
    "\n",
    "axs.set_title('Predictions for '+region+': line=predicted values, x=real values', fontsize=18)\n",
    "axs.plot(range(1, T+DAYS_PREDICTION+1), x[:, 1], linewidth=1 )\n",
    "axs.plot(range(1, T+DAYS_PREDICTION+1), x[:, 2], linewidth=1 ) \n",
    "axs.plot(range(1, T+DAYS_PREDICTION+1), x[:, 3], linewidth=1 ) \n",
    "axs.scatter(range(1, T+1), oI, marker ='x', s=3)\n",
    "axs.scatter(range(1, T+1), oR, marker ='x', s=3)\n",
    "axs.scatter(range(1, T+1), oD, marker ='x', s=3)\n",
    "axs.set_xlim(1, T+DAYS_PREDICTION+1)\n",
    "plt.xlabel('DAYS', fontsize=12)\n",
    "plt.ylabel('PEOPLE', fontsize=12)\n",
    "axs.legend(\"IRDIRD 1\", loc=\"upper left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEIR MODEL + UNSCENTED KALMAN FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_country):\n",
    "    \"\"\"\n",
    "    Compute I and R from cumulative Cases, Recovered and Deaths data.\n",
    "    :param data_country: dataset of the civil protection.\n",
    "    :return: list of tuple daily (I, R) if the number of confirmed cases > CASES CONSIDERED.\n",
    "    \"\"\"\n",
    "    global DATA_SMOOTHING_WINDOW, CASES_CONSIDERED\n",
    "    # The zip () function accepts iterables (they can be zero or more), aggregates them into a tuple and returns them.\n",
    "    # The rolling () function is used to provide the sliding window calculations. Mean in this case.\n",
    "    return [(c - (r + d), r + d) for c, d, r\n",
    "            in zip(data_country['totale_casi'].rolling(DATA_SMOOTHING_WINDOW).mean(),\n",
    "                   data_country['deceduti'].rolling(DATA_SMOOTHING_WINDOW).mean(),\n",
    "                   data_country['dimessi_guariti'].rolling(DATA_SMOOTHING_WINDOW).mean())\n",
    "            if c > CASES_CONSIDERED]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx(x, delta_t):\n",
    "    \n",
    "    global t_inc, t_inf, N\n",
    "\n",
    "    S = x[0]\n",
    "    E = x[2] if x[2] >= 0 else 0\n",
    "    I = x[4]\n",
    "    R0 = x[8] if x[8] >= 0 else 0\n",
    "\n",
    "    dS_temp = (R0 / t_inf) * (S / N) * I * delta_t\n",
    "    dE_temp = (E / t_inc) * delta_t\n",
    "    \n",
    "    dS = - dS_temp\n",
    "    dE = dS_temp - dE_temp\n",
    "    dR = (I / t_inf) * delta_t\n",
    "    dI = dE_temp - dR\n",
    "    dR0 = x[9] * delta_t\n",
    "    ddR0 = x[10] * delta_t\n",
    "\n",
    "    x[1] = dS\n",
    "    x[3] = dE\n",
    "    x[5] = dI\n",
    "    x[7] = dR\n",
    "    x[9] = ddR0\n",
    "\n",
    "    return x + np.array([dS, 0, dE, 0, dI, 0, dR if dR > 0 else 0, 0, dR0, ddR0, 0, 0], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hx(x):\n",
    "    \"\"\"\n",
    "    Measurement from state vector.\n",
    "    :param x: state vector.\n",
    "    :return: measured vector.\n",
    "    \"\"\"\n",
    "    # Create an array with Infected and Removed.\n",
    "    return np.array([x[4], x[6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_diag(*arrs):\n",
    "    \"\"\"Create a block diagonal matrix from provided arrays.\n",
    "\n",
    "    Given the inputs `A`, `B` and `C`, the output will have these\n",
    "    arrays arranged on the diagonal::\n",
    "\n",
    "        [[A, 0, 0],\n",
    "         [0, B, 0],\n",
    "         [0, 0, C]]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A, B, C, ... : array_like, up to 2-D\n",
    "        Input arrays.  A 1-D array or array_like sequence of length `n` is\n",
    "        treated as a 2-D array with shape ``(1,n)``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    D : ndarray\n",
    "        Array with `A`, `B`, `C`, ... on the diagonal.  `D` has the\n",
    "        same dtype as `A`.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If all the input arrays are square, the output is known as a\n",
    "    block diagonal matrix.\n",
    "\n",
    "    Empty sequences (i.e., array-likes of zero size) will not be ignored.\n",
    "    Noteworthy, both [] and [[]] are treated as matrices with shape ``(1,0)``.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from scipy.linalg import block_diag\n",
    "    >>> A = [[1, 0],\n",
    "    ...      [0, 1]]\n",
    "    >>> B = [[3, 4, 5],\n",
    "    ...      [6, 7, 8]]\n",
    "    >>> C = [[7]]\n",
    "    >>> P = np.zeros((2, 0), dtype='int32')\n",
    "    >>> block_diag(A, B, C)\n",
    "    array([[1, 0, 0, 0, 0, 0],\n",
    "           [0, 1, 0, 0, 0, 0],\n",
    "           [0, 0, 3, 4, 5, 0],\n",
    "           [0, 0, 6, 7, 8, 0],\n",
    "           [0, 0, 0, 0, 0, 7]])\n",
    "    >>> block_diag(A, P, B, C)\n",
    "    array([[1, 0, 0, 0, 0, 0],\n",
    "           [0, 1, 0, 0, 0, 0],\n",
    "           [0, 0, 0, 0, 0, 0],\n",
    "           [0, 0, 0, 0, 0, 0],\n",
    "           [0, 0, 3, 4, 5, 0],\n",
    "           [0, 0, 6, 7, 8, 0],\n",
    "           [0, 0, 0, 0, 0, 7]])\n",
    "    >>> block_diag(1.0, [2, 3], [[4, 5], [6, 7]])\n",
    "    array([[ 1.,  0.,  0.,  0.,  0.],\n",
    "           [ 0.,  2.,  3.,  0.,  0.],\n",
    "           [ 0.,  0.,  0.,  4.,  5.],\n",
    "           [ 0.,  0.,  0.,  6.,  7.]])\"\"\"\n",
    "    \n",
    "    if arrs == ():\n",
    "        arrs = ([],)\n",
    "    arrs = [np.atleast_2d(a) for a in arrs]\n",
    "\n",
    "    bad_args = [k for k in range(len(arrs)) if arrs[k].ndim > 2]\n",
    "    if bad_args:\n",
    "        raise ValueError(\"arguments in the following positions have dimension \"\n",
    "                         \"greater than 2: %s\" % bad_args)\n",
    "\n",
    "    shapes = np.array([a.shape for a in arrs])\n",
    "    out_dtype = np.find_common_type([arr.dtype for arr in arrs], [])\n",
    "    out = np.zeros(np.sum(shapes, axis=0), dtype=out_dtype)\n",
    "\n",
    "    r, c = 0, 0\n",
    "    for i, (rr, cc) in enumerate(shapes):\n",
    "        out[r:r + rr, c:c + cc] = arrs[i]\n",
    "        r += rr\n",
    "        c += cc\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_discrete_white_noise(dim, dt, var, block_size):\n",
    "    \"\"\"Returns the Q matrix for the Discrete Constant White Noise\n",
    "    Model. dim may be either 2, 3, or 4 dt is the time step, and sigma\n",
    "    is the variance in the noise.\n",
    "\n",
    "    Q is computed as the G * G^T * variance, where G is the process noise per\n",
    "    time step. In other words, G = [[.5dt^2][dt]]^T for the constant velocity\n",
    "    model.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "    dim : int (2, 3, or 4)\n",
    "        dimension for Q, where the final dimension is (dim x dim)\n",
    "\n",
    "    dt : float, default=1.0\n",
    "        time step in whatever units your filter is using for time. i.e. the\n",
    "        amount of time between innovations\n",
    "\n",
    "    var : float, default=1.0\n",
    "        variance in the noise\n",
    "\n",
    "    block_size : int >= 1\n",
    "        If your state variable contains more than one dimension, such as\n",
    "        a 3d constant velocity model [x x' y y' z z']^T, then Q must be\n",
    "        a block diagonal matrix.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # constant velocity model in a 3D world with a 10 Hz update rate\n",
    "    >>> Q_discrete_white_noise(2, dt=0.1, var=1., block_size=3)\n",
    "    array([[0.000025, 0.0005  , 0.      , 0.      , 0.      , 0.      ],\n",
    "           [0.0005  , 0.01    , 0.      , 0.      , 0.      , 0.      ],\n",
    "           [0.      , 0.      , 0.000025, 0.0005  , 0.      , 0.      ],\n",
    "           [0.      , 0.      , 0.0005  , 0.01    , 0.      , 0.      ],\n",
    "           [0.      , 0.      , 0.      , 0.      , 0.000025, 0.0005  ],\n",
    "           [0.      , 0.      , 0.      , 0.      , 0.0005  , 0.01    ]])\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "\n",
    "    Bar-Shalom. \"Estimation with Applications To Tracking and Navigation\".\n",
    "    John Wiley & Sons, 2001. Page 274.\n",
    "    \"\"\"\n",
    "\n",
    "    if not (dim == 2 or dim == 3 or dim == 4):\n",
    "        raise ValueError(\"dim must be between 2 and 4\")\n",
    "\n",
    "    if dim == 2:\n",
    "        Q = [[.25*dt**4, .5*dt**3],\n",
    "             [ .5*dt**3,    dt**2]]\n",
    "        \n",
    "    elif dim == 3:\n",
    "        Q = [[.25*dt**4, .5*dt**3, .5*dt**2],\n",
    "             [ .5*dt**3,    dt**2,       dt],\n",
    "             [ .5*dt**2,       dt,        1]]\n",
    "    else:\n",
    "        Q = [[(dt**6)/36, (dt**5)/12, (dt**4)/6, (dt**3)/6],\n",
    "             [(dt**5)/12, (dt**4)/4,  (dt**3)/2, (dt**2)/2],\n",
    "             [(dt**4)/6,  (dt**3)/2,   dt**2,     dt],\n",
    "             [(dt**3)/6,  (dt**2)/2 ,  dt,        1.]]\n",
    "    \n",
    "    return block_diag(*[Q]*block_size) * var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    \"\"\"\n",
    "    Smoothing function.\n",
    "    :param y: np.array.\n",
    "    :param box_pts: window (int).\n",
    "    :return: smoother np.array.\n",
    "    \"\"\"\n",
    "    #Return a new array of given shape and type, filled with ones.\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    '''Returns the discrete, linear convolution of two one-dimensional sequences.\n",
    "    The convolution operator is often seen in signal processing, where it models the effect of \n",
    "    a linear time-invariant system on a signal [1]. In probability theory, the sum of two independent \n",
    "    random variables is distributed according to the convolution of their individual distributions.\n",
    "    Mode ‘same’ returns output of length max(M, N). Boundary effects are still visible.'''\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_sigmas_func(n):\n",
    "    \"\"\" Number of sigma points for each variable in the state x\"\"\"\n",
    "    return 2 * n + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(n, alpha, beta, kappa):\n",
    "    \"\"\" Computes the weights for the scaled unscented Kalman filter.\n",
    "    Generates sigma points and weights according to Van der Merwe's. It\n",
    "    parametizes the sigma points using alpha, beta, kappa terms, and\n",
    "    is the version seen in most publications.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    n : int\n",
    "        Dimensionality of the state. 2n+1 weights will be generated.\n",
    "\n",
    "    alpha : float\n",
    "        Determins the spread of the sigma points around the mean.\n",
    "        Usually a small positive value (1e-3) according to [3].\n",
    "\n",
    "    beta : float\n",
    "        Incorporates prior knowledge of the distribution of the mean. For\n",
    "        Gaussian x beta=2 is optimal, according to [3].\n",
    "\n",
    "    kappa : float, default=0.0\n",
    "        Secondary scaling parameter usually set to 0 according to [4],\n",
    "        or to 3-n according to [5].\n",
    "\n",
    "    Return\n",
    "    ----------\n",
    "\n",
    "    Wm : np.array\n",
    "        weight for each sigma point for the mean\n",
    "\n",
    "    Wc : np.array\n",
    "        weight for each sigma point for the covariance \"\"\"\n",
    "    \n",
    "    lambda_ = alpha ** 2 * (n + kappa) - n\n",
    "\n",
    "    c = .5 / (n + lambda_)\n",
    "    #Return a new array of given shape and type, filled with fill_value.\n",
    "    Wc = np.full(num_sigmas_func(n), c)\n",
    "    Wm = np.full(num_sigmas_func(n), c)\n",
    "    Wc[0] = lambda_ / (n + lambda_) + (1 - alpha ** 2 + beta)\n",
    "    Wm[0] = lambda_ / (n + lambda_)\n",
    "    return Wc, Wm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscented_transform(sigmas, Wm, Wc, noise_cov=None):\n",
    "    \"\"\"\n",
    "    Computes unscented transform of a set of sigma points and weights.\n",
    "    returns the mean and covariance in a tuple.\n",
    "\n",
    "    This works in conjunction with the UnscentedKalmanFilter class.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    sigmas: ndarray, of size (n, 2n+1)\n",
    "        2D array of sigma points.\n",
    "\n",
    "    Wm : ndarray [# sigmas per dimension]\n",
    "        Weights for the mean.\n",
    "\n",
    "\n",
    "    Wc : ndarray [# sigmas per dimension]\n",
    "        Weights for the covariance.\n",
    "\n",
    "    noise_cov : ndarray, optional\n",
    "        noise matrix added to the final computed covariance matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    x : ndarray [dimension]\n",
    "        Mean of the sigma points after passing through the transform.\n",
    "\n",
    "    P : ndarray\n",
    "        covariance of the sigma points after passing throgh the transform.\n",
    "    \"\"\"\n",
    "\n",
    "    # dot = \\Sigma^n_1 (W[k]*Xi[k])\n",
    "    x = np.dot(Wm, sigmas)\n",
    "\n",
    "    # new covariance is the sum of the outer product of the residuals\n",
    "    # times the weights\n",
    "\n",
    "    # this is the fast way to do this - see 'else' for the slow way\n",
    "    #numpy.newaxis is used to increase the dimension of the existing array by one more dimension, when used once.\n",
    "    y = sigmas - x[np.newaxis, :]\n",
    "    #np.diag convert vector Wc in diagonal matrix\n",
    "    P = np.dot(y.T, np.dot(np.diag(Wc), y))\n",
    "\n",
    "    if noise_cov is not None:\n",
    "        P += noise_cov\n",
    "\n",
    "    return (x, P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_points(x, P):\n",
    "    global n, alpha, kappa\n",
    "    \"\"\" Computes the sigma points for an unscented Kalman filter\n",
    "    given the mean (x) and covariance(P) of the filter.\n",
    "    Returns tuple of the sigma points and weights.\n",
    "\n",
    "    Works with both scalar and array inputs:\n",
    "    sigma_points (5, 9, 2) # mean 5, covariance 9\n",
    "    sigma_points ([5, 2], 9*eye(2), 2) # means 5 and 2, covariance 9I\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    x : An array-like object of the means of length n\n",
    "    Can be a scalar if 1D.\n",
    "    examples: 1, [1,2], np.array([1,2])\n",
    "\n",
    "    P : scalar, or np.array\n",
    "    Covariance of the filter. If scalar, is treated as eye(n)*P.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    sigmas : np.array, of size (n, 2n+1)\n",
    "    Two dimensional array of sigma points. Each column contains all of\n",
    "    the sigmas for one dimension in the problem space.\n",
    "\n",
    "    Ordered by Xi_0, Xi_{1..n}, Xi_{n+1..2n}\n",
    "    \"\"\"\n",
    "\n",
    "    if n != np.size(x):\n",
    "        raise ValueError(\"expected size(x) {}, but size is {}\".format(n, np.size(x)))\n",
    "\n",
    "    #Returns True if the type of element is a scalar type.\n",
    "    if np.isscalar(x):\n",
    "        #Convert the input to an array.\n",
    "        x = np.asarray([x])\n",
    "\n",
    "    #Returns True if the type of element is a scalar type.\n",
    "    if  np.isscalar(P):\n",
    "        P = np.eye(n)*P\n",
    "    else:\n",
    "        # numpy.atleast_2d() function is used when we want to Convert inputs to arrays with at least two dimension. \n",
    "        # Scalar and 1-dimensional inputs are converted to 2-dimensional arrays, whilst higher-dimensional inputs are preserved.\n",
    "        P = np.atleast_2d(P)\n",
    "\n",
    "    lambda_ = alpha**2 * (n + kappa) - n\n",
    "    #Compute the Cholesky decomposition of a matrix.\n",
    "    # Returns the Cholesky decomposition, A = L L^* or A = U^* U of a Hermitian positive-definite matrix A.\n",
    "    U = scipy.linalg.cholesky((lambda_ + n)*P)\n",
    "\n",
    "    sigmas = np.zeros((2*n+1, n))\n",
    "    sigmas[0] = x\n",
    "    for k in range(n):\n",
    "        # pylint: disable=bad-whitespace\n",
    "        sigmas[k+1]   = np.subtract(x, -U[k])\n",
    "        sigmas[n+k+1] = np.subtract(x, U[k])\n",
    "\n",
    "    return sigmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_variance(x, z, sigmas_f, sigmas_h, Wc):\n",
    "    \"\"\"\n",
    "    Compute cross variance of the state `x` and measurement `z`.\n",
    "    \"\"\"\n",
    "    #np.zeros: Return a new array of given shape and type, filled with zeros.\n",
    "    Pxz = np.zeros((sigmas_f.shape[1], sigmas_h.shape[1]))\n",
    "    # shape: Return the shape of an array.\n",
    "    N = sigmas_f.shape[0]\n",
    "    for i in range(N):\n",
    "        dx = np.subtract(sigmas_f[i], x)\n",
    "        dz = np.subtract(sigmas_h[i], z)\n",
    "        #np.outer: Compute the outer product of two vectors.\n",
    "        Pxz += Wc[i] * np.outer(dx, dz)\n",
    "    return Pxz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, P, Wm, Wc, Q, sigmas_f):\n",
    "    global n, alpha, kappa, dt\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs the predict step of the UKF. On return, x and\n",
    "    P contain the predicted state (x) and covariance (P). \"\"\"\n",
    "\n",
    "    # calculate sigma points for given mean and covariance\n",
    "    sigmas = sigma_points(x, P)\n",
    "\n",
    "    for i, s in enumerate(sigmas):\n",
    "        sigmas_f[i] = fx(s, dt)\n",
    "\n",
    "    #and pass sigmas through the unscented transform to compute prior\n",
    "    x_pior, P_pior = unscented_transform(sigmas_f, Wm, Wc, Q)\n",
    "    return x_pior, P_pior, sigmas_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(z, R, sigmas_f, Wm, Wc, x_prior, P_prior):\n",
    "    global log_likelihood, likelihood, mahalanobis\n",
    "    \"\"\"\n",
    "    Update the UKF with the given measurements. On return,\n",
    "    x and P contain the new post mean and covariance of the filter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    z : numpy.array of shape (dim_z)\n",
    "        measurement vector\n",
    "\n",
    "    R : numpy.array((dim_z, dim_z)), optional\n",
    "        Measurement noise. If provided, overrides R for\n",
    "        this function call.\n",
    "        \n",
    "    sigmas: ndarray, of size (n, 2n+1)\n",
    "        2D array of sigma points.\n",
    "\n",
    "    Wm : ndarray [# sigmas per dimension]\n",
    "        Weights for the mean.\n",
    "\n",
    "\n",
    "    Wc : ndarray [# sigmas per dimension]\n",
    "        Weights for the covariance.\n",
    "        \n",
    "    x_prior: prior predicted state.\n",
    "    \n",
    "    P_prior: prior predicted covariance.\"\"\"\n",
    "\n",
    "    # pass prior sigmas through h(x) to get measurement sigmas\n",
    "    # the shape of sigmas_h will vary if the shape of z varies, so\n",
    "    # recreate each time\n",
    "    sigmas_h = []\n",
    "    for s in sigmas_f:\n",
    "        sigmas_h.append(hx(s))\n",
    "\n",
    "    sigmas_h = np.atleast_2d(sigmas_h)\n",
    "\n",
    "    # mean and covariance of prediction passed through unscented transform\n",
    "    zp, S = unscented_transform(sigmas_h, Wm, Wc, R)\n",
    "\n",
    "    # compute cross variance of the state and the measurements\n",
    "    Pxz = cross_variance(x_prior, zp, sigmas_f, sigmas_h, Wc)\n",
    "\n",
    "    # Kalman gain\n",
    "    K = np.dot(Pxz, np.linalg.inv(S))\n",
    "    # Residual\n",
    "    y = np.subtract(z, zp)   \n",
    "\n",
    "    # update Gaussian state estimate (x, P) posterior state\n",
    "    x = x_prior + np.dot(K, y)\n",
    "    P = P_prior - np.dot(K, np.dot(S, K.T))\n",
    "\n",
    "    # save measurement\n",
    "    #A deep copy constructs a new compound object and then, recursively, inserts copies into it of the objects found in the original.\n",
    "    z = deepcopy(z)\n",
    "\n",
    "    return  x, P, y, z, sigmas_h, S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>stato</th>\n",
       "      <th>denominazione_regione</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>totale_positivi</th>\n",
       "      <th>totale_casi</th>\n",
       "      <th>deceduti</th>\n",
       "      <th>dimessi_guariti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2020-05-29T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>1849</td>\n",
       "      <td>19134</td>\n",
       "      <td>1906</td>\n",
       "      <td>15379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>2020-05-30T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>1612</td>\n",
       "      <td>19146</td>\n",
       "      <td>1916</td>\n",
       "      <td>15618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>2020-05-31T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>1500</td>\n",
       "      <td>19152</td>\n",
       "      <td>1918</td>\n",
       "      <td>15734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>2020-06-01T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>1468</td>\n",
       "      <td>19154</td>\n",
       "      <td>1918</td>\n",
       "      <td>15768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>2020-06-02T17:00:00</td>\n",
       "      <td>ITA</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434905</td>\n",
       "      <td>12.338452</td>\n",
       "      <td>1403</td>\n",
       "      <td>19162</td>\n",
       "      <td>1921</td>\n",
       "      <td>15838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     data stato denominazione_regione        lat       long  \\\n",
       "2015  2020-05-29T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "2036  2020-05-30T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "2057  2020-05-31T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "2078  2020-06-01T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "2099  2020-06-02T17:00:00   ITA                Veneto  45.434905  12.338452   \n",
       "\n",
       "      totale_positivi  totale_casi  deceduti  dimessi_guariti  \n",
       "2015             1849        19134      1906            15379  \n",
       "2036             1612        19146      1916            15618  \n",
       "2057             1500        19152      1918            15734  \n",
       "2078             1468        19154      1918            15768  \n",
       "2099             1403        19162      1921            15838  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_SEIR = cleared_dataframe.head(2100).sort_values([\"denominazione_regione\", \"data\"], ascending = (True, True))\n",
    "#data_SEIR = cleared_dataframe.sort_values([\"denominazione_regione\", \"data\"], ascending = (True, True))\n",
    "data_SEIR.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATIONS = {\n",
    "    #\"Abruzzo\":   1305770,\n",
    "    #\"Basilicata\": 556934,\n",
    "    #\"Calabria\": 1924701,\n",
    "    #\"Campania\": 5785861,\n",
    "    #\"Emilia-Romagna\": 4467118,\n",
    "    #\"Friuli Venezia Giulia\": 1211357,\n",
    "    #\"Lazio\": 5865544,\n",
    "    #\"Liguria\": 1543127,\n",
    "    #\"Lombardia\": 10103969,\n",
    "    #\"Marche\": 1518400,\n",
    "    #\"Molise\": 302265,\n",
    "    #\"P.A. Bolzano\": 106951,\n",
    "    #\"P.A. Trento\": 117417,\n",
    "    #\"Piemonte\": 4341375,\n",
    "    \"Puglia\": 4008296,\n",
    "    #\"Sardegna\": 1630474,\n",
    "    #\"Sicilia\": 4968410,\n",
    "    #\"Toscana\": 3722729,\n",
    "    #\"Umbria\": 880285,\n",
    "    #\"Valle d'Aosta\": 125501,\n",
    "    #\"Veneto\": 4907704\n",
    "}\n",
    "CASES_CONSIDERED = -1\n",
    "DATA_SMOOTHING_WINDOW = 1\n",
    "FORECAST_DAYS = 14\n",
    "AVERAGE_R0_WINDOW = 7\n",
    "SIGMA_CONSIDERED = 0.01\n",
    "\n",
    "# Length of time an individual broadcasts\n",
    "t_inf = 1.5\n",
    "# Length of the incubation period\n",
    "t_inc = 11.5\n",
    "# Reproduction Number\n",
    "R0_init = 5.5 \n",
    "\n",
    "# Unscented Kalman Filter (UKF) setup.\n",
    "dt = 1\n",
    "dim_x, dim_z = 12, 2\n",
    "z_std = (1e-2, 5e-3)\n",
    "var_q = 5e-2\n",
    "n = dim_x\n",
    "alpha = 1e-3\n",
    "beta = 2\n",
    "kappa = 1\n",
    "Wc, Wm = compute_weights(n, alpha, beta, kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puglia\n"
     ]
    }
   ],
   "source": [
    "# Run UKF by populations.\n",
    "results = list()\n",
    "for k, v in POPULATIONS.items():\n",
    "    print(k)\n",
    "    N = v\n",
    "    data_country = data_SEIR[data_SEIR[\"denominazione_regione\"] == k]\n",
    "    zs = preprocess_data(data_country)\n",
    "    \n",
    "    # Initialize\n",
    "    x = np.zeros(dim_x)\n",
    "    P = np.eye(dim_x)\n",
    "    Q = np.eye(dim_x)\n",
    "    R = np.eye(dim_z)  \n",
    "    # Number of sigma points for each variable in the state x\n",
    "    num_sigmas = num_sigmas_func(n)\n",
    "    # sigma points transformed through f(x) and h(x)\n",
    "    # variables for efficiency so we don't recreate every update\n",
    "    sigmas_f = np.zeros((num_sigmas, dim_x))\n",
    "    sigmas_h = np.zeros((num_sigmas, dim_z))\n",
    "    # Kalman gain\n",
    "    K = np.zeros((dim_x, dim_z))\n",
    "    # residual\n",
    "    y = np.zeros((dim_z))\n",
    "    # system uncertainty\n",
    "    S = np.zeros((dim_z, dim_z)) \n",
    "    # these will always be a copy of x,P after predict() is called\n",
    "    x_prior = x.copy()\n",
    "    P_prior = P.copy()\n",
    "    # these will always be a copy of x,P after update() is called\n",
    "    x_post = x.copy()\n",
    "    P_post = P.copy()\n",
    "\n",
    "    # Inital conditions.\n",
    "    x = np.array([v, 0, 0, 0, zs[0][0], 0, zs[0][1], 0, R0_init, 0, 0, 0])\n",
    "    # Noise setup\n",
    "    # factor on uncertainty of initial condition.\n",
    "    P *= 1e0\n",
    "    # process noise\n",
    "    R = np.diag([z ** 2 for z in list(z_std)])\n",
    "    # measurement noise\n",
    "    Q = Q_discrete_white_noise(dim=dim_z, dt=dt, var=var_q ** 2, block_size=int(dim_x / 2))\n",
    "\n",
    "    # Trace the status and covariance (x_post, P_post) of each step prediction+update\n",
    "    R_index = list()\n",
    "    # Trace Reproduction Number of each step prediction+update\n",
    "    R0 = list()\n",
    "    # RUN UKF\n",
    "    # Derive all hidden variables from past and present.\n",
    "    for z in zs:\n",
    "        #Prediction\n",
    "        x, P, sigmas_f = predict(x, P, Wm, Wc, Q, sigmas_f)\n",
    "        x_prior, P_prior = x, P\n",
    "        #Update\n",
    "        x, P, y, z, sigmas_h, S = update(z, R, sigmas_f, Wm, Wc, x_prior, P_prior)\n",
    "        x_post, P_post = x, P\n",
    "        \n",
    "        x, y = x_post, P_post\n",
    "        R0.append(x[8])\n",
    "        R_index.append((x, y))\n",
    "\n",
    "    # Forward prediction\n",
    "    for i in range(FORECAST_DAYS):\n",
    "        # Keep R0 constant for predictions.\n",
    "        x[8] = np.mean(R0[-AVERAGE_R0_WINDOW:])\n",
    "        x[9] = 0\n",
    "        x[10] = 0\n",
    "\n",
    "        try:\n",
    "            x, P, sigmas_f = predict(x, P, Wm, Wc, Q, sigmas_f)\n",
    "            x_prior, P_prior = x, P\n",
    "            x, y = x_prior, P_prior\n",
    "            R_index.append((x, y))\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Cannot predict %d\" % i)\n",
    "    results.append(R_index)\n",
    "\n",
    "# Plot population curves I, E and R.\n",
    "for r, t in zip(results, POPULATIONS.keys()):\n",
    "    xs = range(len(r))\n",
    "\n",
    "    # Pass array of predicted values to smooth function, with a certain smoothing windows\n",
    "    # Use the Smooth function with window size other than 1 to smooth the response data.\n",
    "    I = smooth([a[0][4] for a in r], DATA_SMOOTHING_WINDOW)\n",
    "    # Return the non-negative square-root of an array, element-wise. Multiplied for a costant\n",
    "    sI = [SIGMA_CONSIDERED * np.sqrt(a[1][4, 4]) for a in r]\n",
    "\n",
    "    #R = smooth([a[0][6] for a in r], DATA_SMOOTHING_WINDOW)\n",
    "    #sR = [SIGMA_CONSIDERED * np.sqrt(a[1][6, 6]) for a in r]\n",
    "\n",
    "    # E = smooth([a[0][2] for a in r], DATA_SMOOTHING_WINDOW)\n",
    "    # sE = [SIGMA_CONSIDERED * np.sqrt(a[1][2, 2]) for a in r]\n",
    "\n",
    "    '''Traccia y contro x come linee e / o marker con errorbars attaccati.\n",
    "    x, y definiscono le posizioni dei dati, xerr, yerr definiscono le dimensioni dell'errorbar. Per impostazione predefinita, \n",
    "    questo disegna i marcatori / linee di dati e le errorbars. Usa fmt = 'none' per disegnare errorbars senza alcun indicatore di dati.'''\n",
    "    plt.errorbar(x=xs, y=I, yerr=sI, elinewidth=1, markeredgewidth=1, linewidth=1)\n",
    "    #plt.errorbar(x=xs, y=R, yerr=sR, elinewidth=1, markeredgewidth=1)\n",
    "    # plt.errorbar(x=xs, y=E, yerr=sE, elinewidth=1, markeredgewidth=1)\n",
    "    \n",
    "    temp_data = data_SEIR[data_SEIR['denominazione_regione']==t]\n",
    "    tvec_real_data_L=np.arange(0,len(temp_data[temp_data['denominazione_regione']==t][['data']]))\n",
    "    plt.scatter(tvec_real_data_L, temp_data[temp_data['denominazione_regione']==t][['totale_positivi']], marker ='o', c = 'r',s=5)\n",
    "    #plt.scatter(tvec_real_data_L, temp_data[temp_data['denominazione_regione']==t][['dimessi_guariti']], marker ='o', c = 'g',s=1)\n",
    "    \n",
    "    plt.title(t)\n",
    "    plt.xlabel(\"Days from \"+str(CASES_CONSIDERED)+\" first cases\")\n",
    "    plt.ylabel(\"Persons\")\n",
    "    #plt.legend([\"Real Infected Cases\", \"Real Recovered Cases\", \"Infected\", \"Recovered\", \"Exposed\"])\n",
    "    plt.legend([\"Real Infected Cases\", \"Infected\", \"Recovered\", \"Exposed\"])\n",
    "    plt.grid(True)\n",
    "    plt.figure()\n",
    "\n",
    "# Plot R0.\n",
    "for r, t in zip(results, POPULATIONS.keys()):\n",
    "    xs = range(len(r))\n",
    "    R0 = smooth([a[0][8] for a in r], DATA_SMOOTHING_WINDOW)\n",
    "    sR0 = [SIGMA_CONSIDERED * np.sqrt(a[1][8, 8]) for a in r]\n",
    "    plt.errorbar(x=xs, y=R0, yerr=sR0, elinewidth=1, markeredgewidth=1, linewidth=1)\n",
    "\n",
    "plt.legend(POPULATIONS.keys())\n",
    "plt.xlabel(\"Days from \"+str(CASES_CONSIDERED)+\" first cases\")\n",
    "plt.ylabel(\"R naught\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPz4uddkIro6i8W+Rp8jNmE",
   "collapsed_sections": [],
   "name": "Import Data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
